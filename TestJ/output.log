[2018/03/29-12:40:02.008] [qtp22790969-30] [INFO] [dku.jobs]  - Connects using Shared secret
[2018/03/29-12:40:02.008] [qtp22790969-30] [DEBUG] [dku.jobs]  - Received command : /pintercom/start_session
[2018/03/29-12:40:02.021] [qtp22790969-30] [INFO] [dku.jobs]  - Start Session:
{"jobProjectKey":"CHRISTERADATAEXTRACTTEST","jobId":"Build_aam_bulk_extract_only_folders_2018-03-29T12-39-58.622","jobTicketSecret":"XVvsV4UCLzqC36OHXvk8HebKA5TPr5l8ZvPA4KoU6qY5LJrjPPkTy8kDg5wMUU6V","initiatorAuthContext":{"via":[],"authSource":"USER_FROM_UI","realUserLogin":"chris.halls","userGroups":["data_team"],"userGroupLevelPermissions":{"admin":false,"mayManageUDM":true,"mayCreateProjects":true,"mayWriteUnsafeCode":true,"mayWriteSafeCode":true,"mayCreateAuthenticatedConnections":true,"mayCreateCodeEnvs":false,"mayDevelopPlugins":false,"mayEditLibFolders":false,"mayManageCodeEnvs":false,"mayViewIndexedHiveConnections":false},"userProfile":"DATA_ANALYST"}}
[2018/03/29-12:40:02.024] [qtp22790969-30] [INFO] [dip.tickets.fixed]  - Creating service for single API ticket in auth context: chris.halls
[2018/03/29-12:40:02.037] [qtp22790969-30] [DEBUG] [dku.jobs]  - Command /pintercom/start_session processed in 30ms
[2018/03/29-12:40:02.041] [qtp22790969-31] [INFO] [dku.jobs]  - Connects using Shared secret
[2018/03/29-12:40:02.041] [qtp22790969-31] [DEBUG] [dku.jobs]  - Received command : /pintercom/resolve_job
[2018/03/29-12:40:02.041] [qtp22790969-31] [INFO] [dku.job.slave]  - Starting to resolve job
[2018/03/29-12:40:02.116] [qtp22790969-31] [INFO] [dku.job.slave]  - {
  "type": "NON_RECURSIVE_FORCED_BUILD",
  "projectKey": "CHRISTERADATAEXTRACTTEST",
  "id": "Build_aam_bulk_extract_only_folders_2018-03-29T12-39-58.622",
  "name": "Build aam_bulk_extract_only_folders",
  "initiator": "chris.halls",
  "triggeredFrom": "RECIPE",
  "recipe": "compute_aam_bulk_extract_only_folders",
  "initiationTimestamp": 1522327198622,
  "mailNotification": false,
  "outputs": [
    {
      "type": "DATASET",
      "targetDatasetProjectKey": "CHRISTERADATAEXTRACTTEST",
      "targetDataset": "aam_bulk_extract_only_folders"
    }
  ],
  "refreshHiveMetastore": true
}
[2018/03/29-12:40:02.116] [qtp22790969-31] [INFO] [dku.job.slave]  - Loading recipes
[2018/03/29-12:40:02.123] [qtp22790969-31] [DEBUG] [dku.flow.recipes]  - Building global graph
[2018/03/29-12:40:02.215] [qtp22790969-31] [DEBUG] [dku.flow.recipes]  - Done getting global graph
[2018/03/29-12:40:02.216] [qtp22790969-31] [INFO] [dku.job.slave]  - Recipes loaded, computing job details
[2018/03/29-12:40:02.230] [qtp22790969-31] [INFO] [dku.flow.compute]  - Job output type: DATASET
[2018/03/29-12:40:02.243] [qtp22790969-31] [INFO] [dku.flow.compute]  - computing job from target CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders partition NP
[2018/03/29-12:40:02.249] [qtp22790969-31] [INFO] [dku.flow.compute]  - Refreshing CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders/NP with recipe compute_aam_bulk_extract_only_folders
[2018/03/29-12:40:02.259] [qtp22790969-31] [INFO] [dku.flow.compute.op] activity compute_aam_bulk_extract_only_folders_<partition:NP> - Compute output partitions for subgraph, with target : CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders and partition: NP
[2018/03/29-12:40:02.260] [qtp22790969-31] [INFO] [dku.flow.compute.op] activity compute_aam_bulk_extract_only_folders_<partition:NP> - Target CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders is not partitioned
[2018/03/29-12:40:02.260] [qtp22790969-31] [INFO] [dku.flow.compute.op] activity compute_aam_bulk_extract_only_folders_<partition:NP> - Add output partition for CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders : NP
[2018/03/29-12:40:02.260] [qtp22790969-31] [INFO] [dku.flow.compute] activity compute_aam_bulk_extract_only_folders_<partition:NP> - computed output partitions: {CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders=<partition:NP>}
[2018/03/29-12:40:02.265] [qtp22790969-31] [INFO] [dku.flow.compute.ip] activity compute_aam_bulk_extract_only_folders_<partition:NP> - 0 dependency for CHRISTERADATAEXTRACTTEST.aam_bulk_extract
[2018/03/29-12:40:02.265] [qtp22790969-31] [INFO] [dku.flow.compute.ip] activity compute_aam_bulk_extract_only_folders_<partition:NP> - source CHRISTERADATAEXTRACTTEST.aam_bulk_extract is not partitioned, including the global partition
[2018/03/29-12:40:02.265] [qtp22790969-31] [INFO] [dku.flow.compute.ip] activity compute_aam_bulk_extract_only_folders_<partition:NP> - 0 dependency for CHRISTERADATAEXTRACTTEST.aam_trait_metadata_filtered
[2018/03/29-12:40:02.265] [qtp22790969-31] [INFO] [dku.flow.compute.ip] activity compute_aam_bulk_extract_only_folders_<partition:NP> - source CHRISTERADATAEXTRACTTEST.aam_trait_metadata_filtered is not partitioned, including the global partition
[2018/03/29-12:40:02.266] [qtp22790969-31] [INFO] [dku.flow.compute] activity compute_aam_bulk_extract_only_folders_<partition:NP> - computed input partitions : {CHRISTERADATAEXTRACTTEST.aam_bulk_extract=[<partition:NP>], CHRISTERADATAEXTRACTTEST.aam_trait_metadata_filtered=[<partition:NP>]}
[2018/03/29-12:40:02.269] [qtp22790969-31] [INFO] [dku.flow.compute]  - Before prune, job looks like:
JOB
  ACTIVITY ROOT
    DEPS
      ACTIVITY compute_aam_bulk_extract_only_folders_NP
        SGID: compute_aam_bulk_extract_only_folders_NP
        SRC: CHRISTERADATAEXTRACTTEST.aam_bulk_extract (partitions: NP)
        SRC: CHRISTERADATAEXTRACTTEST.aam_trait_metadata_filtered (partitions: NP)
        DST: CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders (partition: NP)

[2018/03/29-12:40:02.270] [qtp22790969-31] [INFO] [dku.flow.compute]  - After cleanup of implicit recipes, job looks like:
JOB
  ACTIVITY ROOT
    DEPS
      ACTIVITY compute_aam_bulk_extract_only_folders_NP
        SGID: compute_aam_bulk_extract_only_folders_NP
        SRC: CHRISTERADATAEXTRACTTEST.aam_bulk_extract (partitions: NP)
        SRC: CHRISTERADATAEXTRACTTEST.aam_trait_metadata_filtered (partitions: NP)
        DST: CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders (partition: NP)

[2018/03/29-12:40:02.271] [qtp22790969-31] [INFO] [dku.flow.compute]  - Job project: CHRISTERADATAEXTRACTTEST
[2018/03/29-12:40:02.289] [qtp22790969-31] [INFO] [dku.flow.compute]  - Doing job pruning according to settings
[2018/03/29-12:40:02.289] [qtp22790969-31] [INFO] [dku.flow.compute]  - not pruning activity, job type is NON_RECURSIVE_FORCED_BUILD
[2018/03/29-12:40:02.290] [qtp22790969-31] [INFO] [dku.flow.compute]  - After prune, job looks like that
[2018/03/29-12:40:02.290] [qtp22790969-31] [INFO] [dku.flow.compute]  - JOB
  ACTIVITY ROOT
    DEPS
      ACTIVITY compute_aam_bulk_extract_only_folders_NP
        SGID: compute_aam_bulk_extract_only_folders_NP
        SRC: CHRISTERADATAEXTRACTTEST.aam_bulk_extract (partitions: NP)
        SRC: CHRISTERADATAEXTRACTTEST.aam_trait_metadata_filtered (partitions: NP)
        DST: CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders (partition: NP)

[2018/03/29-12:40:02.291] [qtp22790969-31] [INFO] [dku.flow.compute]  - Done building final job graph
[2018/03/29-12:40:02.291] [qtp22790969-31] [INFO] [dku.job.slave]  - Done computing job data, dumping graph
[2018/03/29-12:40:02.291] [qtp22790969-31] [INFO] [dku.job.slave]  - JOB
  ACTIVITY ROOT
    DEPS
      ACTIVITY compute_aam_bulk_extract_only_folders_NP
        SGID: compute_aam_bulk_extract_only_folders_NP
        SRC: CHRISTERADATAEXTRACTTEST.aam_bulk_extract (partitions: NP)
        SRC: CHRISTERADATAEXTRACTTEST.aam_trait_metadata_filtered (partitions: NP)
        DST: CHRISTERADATAEXTRACTTEST.aam_bulk_extract_only_folders (partition: NP)

[2018/03/29-12:40:02.294] [qtp22790969-31] [INFO] [dku.job.slave]  - Job has the following sources: [{"projectKey":"CHRISTERADATAEXTRACTTEST","type":"DATASET","id":"aam_bulk_extract"},{"projectKey":"CHRISTERADATAEXTRACTTEST","type":"DATASET","id":"aam_trait_metadata_filtered"}]
[2018/03/29-12:40:02.294] [qtp22790969-31] [INFO] [dku.job.slave]  - Trying to obtain grant: datasetread::READ_DATA::CHRISTERADATAEXTRACTTEST.aam_bulk_extract
[2018/03/29-12:40:02.299] [qtp22790969-31] [INFO] [dku.job.slave]  - Trying to obtain grant: datasetread::READ_DATA::CHRISTERADATAEXTRACTTEST.aam_trait_metadata_filtered
[2018/03/29-12:40:02.312] [qtp22790969-31] [DEBUG] [dku.jobs]  - Command /pintercom/resolve_job processed in 271ms
[2018/03/29-12:40:02.316] [qtp22790969-30] [INFO] [dku.jobs]  - Connects using Shared secret
[2018/03/29-12:40:02.317] [qtp22790969-30] [DEBUG] [dku.jobs]  - Received command : /pintercom/run_fully
[2018/03/29-12:40:02.324] [qtp22790969-30] [INFO] [dku.job.slave]  - Job run started in kernel with pid 3964
[2018/03/29-12:40:02.325] [qtp22790969-30] [INFO] [dku.flow.jobrunner]  - Creating 50 activity runner thread(s).
[2018/03/29-12:40:02.326] [qtp22790969-30] [INFO] [dku.flow.jobrunner]  - Starting activity executor threads
[2018/03/29-12:40:02.328] [ActivityExecutor-35] [INFO] [dku.flow.jobrunner]  - About to run compute_aam_bulk_extract_only_folders_NP
[2018/03/29-12:40:02.333] [qtp22790969-30] [INFO] [dku.flow.jobrunner]  - Waiting for activity executor threads
[2018/03/29-12:40:02.340] [ActivityExecutor-35] [INFO] [dku.flow.jobrunner] running compute_aam_bulk_extract_only_folders_NP - Allocated a slot for this activity!
[2018/03/29-12:40:02.341] [ActivityExecutor-35] [INFO] [dku.flow.jobrunner] running compute_aam_bulk_extract_only_folders_NP - Run activity
[2018/03/29-12:40:02.356] [ActivityExecutor-35] [INFO] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - Executing default pre-activity lifecycle hook
[2018/03/29-12:40:02.420] [ActivityExecutor-35] [DEBUG] [dku.datasets.hdfs] running compute_aam_bulk_extract_only_folders_NP - Built HDFS dataset handler dataset=CHRISTERADATAEXTRACTTEST.aam_bulk_extract connection=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db resolvedPath=/adobe_aam_parquet connRootSA=nullconnRootWithinSA=/apps/hive/warehouse/data_dev.db configuredRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet effectiveRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:02.429] [ActivityExecutor-35] [DEBUG] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Build HDFSProvider conn=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db pWCR=/adobe_aam_parquet crSA=null crWSA=/apps/hive/warehouse/data_dev.db rpWSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:02.813] [ActivityExecutor-35] [DEBUG] [dku.hadoop] running compute_aam_bulk_extract_only_folders_NP - Initializing Hadoop FS with context UGI: dataiku (auth:SIMPLE) (login: dataiku (auth:SIMPLE))
4.296: [GC (Metadata GC Threshold) [PSYoungGen: 228820K->13926K(286208K)] 248809K->33987K(714752K), 0.0087296 secs] [Times: user=0.04 sys=0.01, real=0.01 secs] 
4.305: [Full GC (Metadata GC Threshold) [PSYoungGen: 13926K->0K(286208K)] [ParOldGen: 20060K->20924K(714752K)] 33987K->20924K(1000960K), [Metaspace: 34716K->34716K(1081344K)], 0.0376293 secs] [Times: user=0.15 sys=0.00, real=0.04 secs] 
[2018/03/29-12:40:03.656] [ActivityExecutor-35] [DEBUG] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Built Hadoop FS for: null -> DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1642457693_35, ugi=dataiku (auth:SIMPLE)]]
[2018/03/29-12:40:03.766] [ActivityExecutor-35] [INFO] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - Checking if sources are ready
5.072: [GC (Allocation Failure) [PSYoungGen: 245760K->8716K(356352K)] 266684K->29641K(1071104K), 0.0076468 secs] [Times: user=0.01 sys=0.01, real=0.01 secs] 
[2018/03/29-12:40:03.795] [ActivityExecutor-35] [DEBUG] [dku.datasets.hdfs] running compute_aam_bulk_extract_only_folders_NP - Built HDFS dataset handler dataset=CHRISTERADATAEXTRACTTEST.aam_bulk_extract connection=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db resolvedPath=/adobe_aam_parquet connRootSA=nullconnRootWithinSA=/apps/hive/warehouse/data_dev.db configuredRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet effectiveRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:03.798] [ActivityExecutor-35] [INFO] [dku.datasets.hdfs] running compute_aam_bulk_extract_only_folders_NP - Enumerating Filesystem dataset prefix=
[2018/03/29-12:40:03.798] [ActivityExecutor-35] [DEBUG] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Build HDFSProvider conn=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db pWCR=/adobe_aam_parquet crSA=null crWSA=/apps/hive/warehouse/data_dev.db rpWSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:03.799] [ActivityExecutor-35] [DEBUG] [dku.hadoop] running compute_aam_bulk_extract_only_folders_NP - Initializing Hadoop FS with context UGI: dataiku (auth:SIMPLE) (login: dataiku (auth:SIMPLE))
[2018/03/29-12:40:03.828] [ActivityExecutor-35] [DEBUG] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Built Hadoop FS for: null -> DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1642457693_35, ugi=dataiku (auth:SIMPLE)]]
[2018/03/29-12:40:03.830] [ActivityExecutor-35] [INFO] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Enumerating HDFS Filesystem from root : /apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:03.847] [ActivityExecutor-35] [INFO] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - HDFS-enumerate depth=0 curContent=52
[2018/03/29-12:40:03.854] [ActivityExecutor-35] [INFO] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Done HDFS enumeration: nb_paths=52 total_size=40376386618
[2018/03/29-12:40:03.865] [ActivityExecutor-35] [INFO] [dku.datasets.file] running compute_aam_bulk_extract_only_folders_NP - Building Filesystem handler config: {"connection":"filesystem_managed","path":"CHRISTERADATAEXTRACTTEST/aam_trait_metadata_filtered","notReadyIfEmpty":false,"filesSelectionRules":{"mode":"ALL","excludeRules":[],"includeRules":[],"explicitFiles":[]}}
[2018/03/29-12:40:03.866] [ActivityExecutor-35] [INFO] [dku.datasets.ftplike] running compute_aam_bulk_extract_only_folders_NP - Enumerating Filesystem dataset prefix=
[2018/03/29-12:40:03.869] [ActivityExecutor-35] [DEBUG] [dku.fs.local] running compute_aam_bulk_extract_only_folders_NP - Enumerating local filesystem prefix=/
[2018/03/29-12:40:03.870] [ActivityExecutor-35] [DEBUG] [dku.fs.local] running compute_aam_bulk_extract_only_folders_NP - Enumeration done nb_paths=1 size=22485
[2018/03/29-12:40:03.871] [ActivityExecutor-35] [DEBUG] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - Computing hashes to propagate BEFORE activity
[2018/03/29-12:40:03.880] [ActivityExecutor-35] [DEBUG] [dku.datasets.hdfs] running compute_aam_bulk_extract_only_folders_NP - Built HDFS dataset handler dataset=CHRISTERADATAEXTRACTTEST.aam_bulk_extract connection=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db resolvedPath=/adobe_aam_parquet connRootSA=nullconnRootWithinSA=/apps/hive/warehouse/data_dev.db configuredRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet effectiveRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:03.880] [ActivityExecutor-35] [INFO] [dku.datasets.hdfs] running compute_aam_bulk_extract_only_folders_NP - Enumerating Filesystem dataset prefix=
[2018/03/29-12:40:03.880] [ActivityExecutor-35] [DEBUG] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Build HDFSProvider conn=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db pWCR=/adobe_aam_parquet crSA=null crWSA=/apps/hive/warehouse/data_dev.db rpWSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:03.881] [ActivityExecutor-35] [DEBUG] [dku.hadoop] running compute_aam_bulk_extract_only_folders_NP - Initializing Hadoop FS with context UGI: dataiku (auth:SIMPLE) (login: dataiku (auth:SIMPLE))
[2018/03/29-12:40:03.910] [ActivityExecutor-35] [DEBUG] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Built Hadoop FS for: null -> DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1642457693_35, ugi=dataiku (auth:SIMPLE)]]
[2018/03/29-12:40:03.913] [ActivityExecutor-35] [INFO] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Enumerating HDFS Filesystem from root : /apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:03.919] [ActivityExecutor-35] [INFO] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - HDFS-enumerate depth=0 curContent=52
[2018/03/29-12:40:03.923] [ActivityExecutor-35] [INFO] [dku.fsproviders.hdfs] running compute_aam_bulk_extract_only_folders_NP - Done HDFS enumeration: nb_paths=52 total_size=40376386618
[2018/03/29-12:40:03.929] [ActivityExecutor-35] [INFO] [dku.datasets.file] running compute_aam_bulk_extract_only_folders_NP - Building Filesystem handler config: {"connection":"filesystem_managed","path":"CHRISTERADATAEXTRACTTEST/aam_trait_metadata_filtered","notReadyIfEmpty":false,"filesSelectionRules":{"mode":"ALL","excludeRules":[],"includeRules":[],"explicitFiles":[]}}
[2018/03/29-12:40:03.929] [ActivityExecutor-35] [INFO] [dku.datasets.ftplike] running compute_aam_bulk_extract_only_folders_NP - Enumerating Filesystem dataset prefix=
[2018/03/29-12:40:03.931] [ActivityExecutor-35] [DEBUG] [dku.fs.local] running compute_aam_bulk_extract_only_folders_NP - Enumerating local filesystem prefix=/
[2018/03/29-12:40:03.932] [ActivityExecutor-35] [DEBUG] [dku.fs.local] running compute_aam_bulk_extract_only_folders_NP - Enumeration done nb_paths=1 size=22485
[2018/03/29-12:40:03.933] [ActivityExecutor-35] [DEBUG] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - Recorded 2 hashes before activity run
[2018/03/29-12:40:03.934] [ActivityExecutor-35] [DEBUG] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - Building recipe runner of type
[2018/03/29-12:40:03.959] [ActivityExecutor-35] [INFO] [dku.recipe.join] running compute_aam_bulk_extract_only_folders_NP - SET PAYLOAD: {
  "joins": [
    {
      "table2": 1,
      "table1": 0,
      "conditionsMode": "AND",
      "rightLimit": {
        "decisionColumn": {}
      },
      "type": "INNER",
      "outerJoinOnTheLeft": true,
      "on": [
        {
          "column1": {
            "name": "trait",
            "table": 0
          },
          "dateDiffUnit": "DAY",
          "column2": {
            "name": "sid",
            "table": 1
          },
          "maxMatches": 1,
          "caseInsensitive": false,
          "maxDistance": 1,
          "normalizeText": false,
          "type": "EQ",
          "strict": false
        },
        {
          "column1": {
            "name": "filename",
            "table": 0
          },
          "dateDiffUnit": "DAY",
          "column2": {
            "name": "filename",
            "table": 1
          },
          "maxMatches": 1,
          "caseInsensitive": false,
          "maxDistance": 0,
          "normalizeText": false,
          "type": "EQ",
          "strict": false
        }
      ]
    }
  ],
  "selectedColumns": [
    {
      "name": "aamid_hash",
      "type": "string",
      "table": 0
    },
    {
      "name": "trait",
      "type": "string",
      "table": 0
    },
    {
      "name": "region_code",
      "type": "string",
      "table": 0
    },
    {
      "name": "timestamp_as_date",
      "type": "string",
      "table": 0
    },
    {
      "name": "name",
      "type": "string",
      "table": 1
    }
  ],
  "engineParams": {
    "hive": {
      "skipPrerunValidate": false,
      "hiveconf": [],
      "inheritConf": "default",
      "addDkuUdf": false,
      "executionEngine": "HIVESERVER2"
    },
    "impala": {
      "forceStreamMode": true
    },
    "lowerCaseSchemaIfEngineRequiresIt": true,
    "sparkSQL": {
      "pipelineAllowMerge": true,
      "useGlobalMetastore": false,
      "pipelineAllowStart": true,
      "readParams": {
        "map": {}
      },
      "overwriteOutputSchema": false,
      "sparkConfig": {
        "inheritConf": "default",
        "conf": []
      }
    }
  },
  "virtualInputs": [
    {
      "preFilter": {
        "distinct": false,
        "enabled": false
      },
      "autoSelectColumns": false,
      "index": 0,
      "computedColumns": []
    },
    {
      "preFilter": {
        "distinct": false,
        "enabled": false
      },
      "autoSelectColumns": false,
      "index": 1,
      "computedColumns": []
    }
  ],
  "computedColumns": [],
  "postFilter": {
    "$status": {
      "schema": {
        "columns": [
          {
            "timestampNoTzAsDate": false,
            "name": "aamid_hash",
            "type": "string",
            "maxLength": -1
          },
          {
            "timestampNoTzAsDate": false,
            "name": "trait",
            "type": "string",
            "maxLength": -1
          },
          {
            "timestampNoTzAsDate": false,
            "name": "region_code",
            "type": "string",
            "maxLength": -1
          },
          {
            "timestampNoTzAsDate": false,
            "name": "timestamp_as_date",
            "type": "string",
            "maxLength": -1
          },
          {
            "timestampNoTzAsDate": false,
            "name": "name",
            "type": "string",
            "maxLength": -1
          }
        ],
        "userModified": false
      }
    }
  },
  "enableAutoCastInJoinConditions": false
}
[2018/03/29-12:40:03.993] [ActivityExecutor-35] [INFO] [com.dataiku.dip.impala.ImpalaConfigurator] running compute_aam_bulk_extract_only_folders_NP - Impala support is disabled
[2018/03/29-12:40:03.999] [ActivityExecutor-35] [INFO] [com.dataiku.dip.impala.ImpalaConfigurator] running compute_aam_bulk_extract_only_folders_NP - Impala support is disabled
[2018/03/29-12:40:04.044] [ActivityExecutor-35] [INFO] [dku.recipes.engines] running compute_aam_bulk_extract_only_folders_NP - Resolved preferences projectKey=CHRISTERADATAEXTRACTTEST recipeType=join global={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}} project={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}} pplusg={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}} recipe=null resolved={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}}
[2018/03/29-12:40:04.044] [ActivityExecutor-35] [INFO] [dku.recipes.visualsql] running compute_aam_bulk_extract_only_folders_NP - Auto-selected recipe engine: DSS
[2018/03/29-12:40:04.067] [ActivityExecutor-35] [INFO] [dku.recipes.engines] running compute_aam_bulk_extract_only_folders_NP - Resolved preferences projectKey=CHRISTERADATAEXTRACTTEST recipeType=join global={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}} project={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}} pplusg={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}} recipe=null resolved={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}}
[2018/03/29-12:40:04.070] [ActivityExecutor-35] [INFO] [com.dataiku.dip.impala.ImpalaConfigurator] running compute_aam_bulk_extract_only_folders_NP - Impala support is disabled
[2018/03/29-12:40:04.076] [ActivityExecutor-35] [INFO] [com.dataiku.dip.impala.ImpalaConfigurator] running compute_aam_bulk_extract_only_folders_NP - Impala support is disabled
[2018/03/29-12:40:04.088] [ActivityExecutor-35] [INFO] [dku.recipes.visualsql] running compute_aam_bulk_extract_only_folders_NP - Auto-selected recipe engine: DSS
[2018/03/29-12:40:04.090] [ActivityExecutor-35] [INFO] [dku.recipes.engines] running compute_aam_bulk_extract_only_folders_NP - Resolved preferences projectKey=CHRISTERADATAEXTRACTTEST recipeType=join global={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}} project={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}} pplusg={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}} recipe=null resolved={"forbiddenEngines":[],"enginesPreferenceOrder":[],"forbiddenByRecipeType":{},"preferenceByRecipeType":{}}
[2018/03/29-12:40:04.093] [ActivityExecutor-35] [INFO] [com.dataiku.dip.impala.ImpalaConfigurator] running compute_aam_bulk_extract_only_folders_NP - Impala support is disabled
[2018/03/29-12:40:04.103] [ActivityExecutor-35] [INFO] [com.dataiku.dip.impala.ImpalaConfigurator] running compute_aam_bulk_extract_only_folders_NP - Impala support is disabled
[2018/03/29-12:40:04.115] [ActivityExecutor-35] [INFO] [dku.recipes.visualsql] running compute_aam_bulk_extract_only_folders_NP - Auto-selected recipe engine: DSS
[2018/03/29-12:40:04.119] [ActivityExecutor-35] [DEBUG] [dku.datasets.hdfs] running compute_aam_bulk_extract_only_folders_NP - Built HDFS dataset handler dataset=CHRISTERADATAEXTRACTTEST.aam_bulk_extract connection=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db resolvedPath=/adobe_aam_parquet connRootSA=nullconnRootWithinSA=/apps/hive/warehouse/data_dev.db configuredRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet effectiveRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:04.121] [ActivityExecutor-35] [DEBUG] [dku.datasets.hdfs] running compute_aam_bulk_extract_only_folders_NP - Built HDFS dataset handler dataset=CHRISTERADATAEXTRACTTEST.aam_bulk_extract connection=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db resolvedPath=/adobe_aam_parquet connRootSA=nullconnRootWithinSA=/apps/hive/warehouse/data_dev.db configuredRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet effectiveRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:04.177] [ActivityExecutor-35] [INFO] [dku.recipe.visual] running compute_aam_bulk_extract_only_folders_NP - Selected engine type: DSS
[2018/03/29-12:40:04.177] [ActivityExecutor-35] [INFO] [dku.recipe.join] running compute_aam_bulk_extract_only_folders_NP - Using H2 implementation
[2018/03/29-12:40:04.203] [ActivityExecutor-35] [INFO] [dku.connections.sql.provider] running compute_aam_bulk_extract_only_folders_NP - Connecting to jdbc:h2:/Dataiku/jobs/CHRISTERADATAEXTRACTTEST/Build_aam_bulk_extract_only_folders_2018-03-29T12-39-58.622/compute_aam_bulk_extract_only_folders_NP/dataset-to-h2/s7YjA5IRQufOjIfoKzGT/dataset with props: {}
[2018/03/29-12:40:04.204] [ActivityExecutor-35] [DEBUG] [dku.connections.sql.provider] running compute_aam_bulk_extract_only_folders_NP - Driver version 1.4
[2018/03/29-12:40:04.364] [ActivityExecutor-35] [INFO] [dku.connections.sql.provider] running compute_aam_bulk_extract_only_folders_NP - Driver H2 JDBC Driver (JDBC 4.0) 1.4.195 (2017-04-23) (1.4)
[2018/03/29-12:40:04.365] [ActivityExecutor-35] [INFO] [dku.connections.sql.provider] running compute_aam_bulk_extract_only_folders_NP - Database H2 1.4.195 (2017-04-23) (1.4) rowSize=0 stmts=0
[2018/03/29-12:40:04.365] [ActivityExecutor-35] [DEBUG] [dku.connections.sql.provider] running compute_aam_bulk_extract_only_folders_NP - Set autocommit=false on conn=h2connection
[2018/03/29-12:40:04.368] [ActivityExecutor-35] [INFO] [dku.h2] running compute_aam_bulk_extract_only_folders_NP - Init H2 recipe runner
[2018/03/29-12:40:04.372] [ActivityExecutor-35] [INFO] [dku.datasets.file] running compute_aam_bulk_extract_only_folders_NP - Building Filesystem handler config: {"connection":"filesystem_managed","path":"CHRISTERADATAEXTRACTTEST/aam_bulk_extract_only_folders","notReadyIfEmpty":false,"filesSelectionRules":{"mode":"ALL","excludeRules":[],"includeRules":[],"explicitFiles":[]}}
[2018/03/29-12:40:04.372] [ActivityExecutor-35] [INFO] [dku.h2] running compute_aam_bulk_extract_only_folders_NP - Write mode : OVERWRITE
[2018/03/29-12:40:04.373] [ActivityExecutor-35] [INFO] [dku.datasets.ftplike] running compute_aam_bulk_extract_only_folders_NP - Clear partitions
[2018/03/29-12:40:04.375] [ActivityExecutor-35] [INFO] [dku.datasets.ftplike] running compute_aam_bulk_extract_only_folders_NP - Clearing partition as a folder : 'NP'
[2018/03/29-12:40:04.377] [ActivityExecutor-35] [INFO] [dku.datasets.ftplike] running compute_aam_bulk_extract_only_folders_NP - Done clearing partition 'NP'
[2018/03/29-12:40:04.378] [ActivityExecutor-35] [INFO] [dku.h2] running compute_aam_bulk_extract_only_folders_NP - Cleared FS dataset. Write mode : APPEND
[2018/03/29-12:40:04.378] [ActivityExecutor-35] [DEBUG] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - Recipe runner built, will use 1 thread(s)
[2018/03/29-12:40:04.379] [ActivityExecutor-35] [DEBUG] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - Starting execution thread: com.dataiku.dip.dataflow.exec.join.JoinRecipeRunner@1bf61a56
[2018/03/29-12:40:04.380] [ActivityExecutor-35] [DEBUG] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - Execution threads started, waiting for activity end
[2018/03/29-12:40:04.380] [FRT-95-FlowRunnable] [INFO] [dku.flow.activity] act.compute_aam_bulk_extract_only_folders_NP - Run thread for activity compute_aam_bulk_extract_only_folders_NP starting
[2018/03/29-12:40:04.380] [FRT-95-FlowRunnable] [INFO] [dku.recipe.visual] act.compute_aam_bulk_extract_only_folders_NP - Selected executor: com.dataiku.dip.dataflow.exec.join.JoinRecipeRunner$1
[2018/03/29-12:40:04.392] [FRT-95-FlowRunnable] [INFO] [dku.h2loader] act.compute_aam_bulk_extract_only_folders_NP - Dumping dataset to CSV for H2...
[2018/03/29-12:40:04.394] [FRT-95-FlowRunnable] [DEBUG] [dku.datasets.hdfs] act.compute_aam_bulk_extract_only_folders_NP - Built HDFS dataset handler dataset=CHRISTERADATAEXTRACTTEST.aam_bulk_extract connection=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db resolvedPath=/adobe_aam_parquet connRootSA=nullconnRootWithinSA=/apps/hive/warehouse/data_dev.db configuredRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet effectiveRootPathWithinSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:04.395] [FRT-95-FlowRunnable] [INFO] [dku.datasets.hdfs] act.compute_aam_bulk_extract_only_folders_NP - Enumerating Filesystem dataset prefix=
[2018/03/29-12:40:04.395] [FRT-95-FlowRunnable] [DEBUG] [dku.fsproviders.hdfs] act.compute_aam_bulk_extract_only_folders_NP - Build HDFSProvider conn=hive_data_dev cpr=/apps/hive/warehouse/data_dev.db pWCR=/adobe_aam_parquet crSA=null crWSA=/apps/hive/warehouse/data_dev.db rpWSA=/apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:04.396] [FRT-95-FlowRunnable] [DEBUG] [dku.hadoop] act.compute_aam_bulk_extract_only_folders_NP - Initializing Hadoop FS with context UGI: dataiku (auth:SIMPLE) (login: dataiku (auth:SIMPLE))
[2018/03/29-12:40:04.427] [FRT-95-FlowRunnable] [DEBUG] [dku.fsproviders.hdfs] act.compute_aam_bulk_extract_only_folders_NP - Built Hadoop FS for: null -> DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_1642457693_35, ugi=dataiku (auth:SIMPLE)]]
[2018/03/29-12:40:04.429] [FRT-95-FlowRunnable] [INFO] [dku.fsproviders.hdfs] act.compute_aam_bulk_extract_only_folders_NP - Enumerating HDFS Filesystem from root : /apps/hive/warehouse/data_dev.db/adobe_aam_parquet
[2018/03/29-12:40:04.435] [FRT-95-FlowRunnable] [INFO] [dku.fsproviders.hdfs] act.compute_aam_bulk_extract_only_folders_NP - HDFS-enumerate depth=0 curContent=52
[2018/03/29-12:40:04.437] [FRT-95-FlowRunnable] [INFO] [dku.fsproviders.hdfs] act.compute_aam_bulk_extract_only_folders_NP - Done HDFS enumeration: nb_paths=52 total_size=40376386618
[2018/03/29-12:40:04.437] [FRT-95-FlowRunnable] [INFO] [dku.input.push] act.compute_aam_bulk_extract_only_folders_NP - USTP: push selection.method=FULL records=-1 ratio=0.02 col=null
[2018/03/29-12:40:04.440] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Run Parquet format extractor without limit
[2018/03/29-12:40:04.447] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000000_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:04.525] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:04.570] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[2018/03/29-12:40:05.044] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.048] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
6.386: [GC (Allocation Failure) [PSYoungGen: 324620K->10575K(356352K)] 345545K->31508K(1071104K), 0.0083413 secs] [Times: user=0.03 sys=0.01, real=0.01 secs] 
[2018/03/29-12:40:05.252] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=4
[2018/03/29-12:40:05.252] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=4 totalRecords=4
[2018/03/29-12:40:05.254] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000001_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.279] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.281] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.291] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.291] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.298] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=6
[2018/03/29-12:40:05.298] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=6 totalRecords=6
[2018/03/29-12:40:05.299] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000003_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.323] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.324] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.331] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.331] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.338] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=7
[2018/03/29-12:40:05.339] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=7 totalRecords=7
[2018/03/29-12:40:05.340] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000004_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.367] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.369] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.376] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.376] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.390] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=77
[2018/03/29-12:40:05.390] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=77 totalRecords=77
[2018/03/29-12:40:05.392] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000005_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.421] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.423] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.429] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.430] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.437] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=120
[2018/03/29-12:40:05.437] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=120 totalRecords=120
[2018/03/29-12:40:05.438] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000006_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.461] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.463] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.469] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.471] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.478] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=181
[2018/03/29-12:40:05.478] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=181 totalRecords=181
[2018/03/29-12:40:05.479] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000007_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.502] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.504] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.511] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.512] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.523] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=241
[2018/03/29-12:40:05.523] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=241 totalRecords=241
[2018/03/29-12:40:05.525] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000008_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.558] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.561] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.568] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.569] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.596] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=1229
[2018/03/29-12:40:05.596] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=1229 totalRecords=1229
[2018/03/29-12:40:05.598] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000009_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.624] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.626] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.631] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.632] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.661] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=2281
[2018/03/29-12:40:05.661] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=2281 totalRecords=2281
[2018/03/29-12:40:05.663] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000010_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.686] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.688] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.695] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.695] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.715] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=3235
[2018/03/29-12:40:05.715] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=3235 totalRecords=3235
[2018/03/29-12:40:05.717] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000011_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.741] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.743] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.749] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.749] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.780] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=4485
[2018/03/29-12:40:05.780] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=4485 totalRecords=4485
[2018/03/29-12:40:05.782] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000012_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.805] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.807] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.814] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.814] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.829] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=5587
[2018/03/29-12:40:05.830] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=5587 totalRecords=5587
[2018/03/29-12:40:05.832] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000013_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.865] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.867] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
Mar 29, 2018 12:40:04 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:04 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 4 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 34 ms. row count = 4
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 2 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 2
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 70 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 70
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 43 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 43
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 61 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 61
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 60 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 60
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 988 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 988
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1052 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 1052
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 954 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 954
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1250 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 16 ms. row count = 1250
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1102 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 1102
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
[2018/03/29-12:40:05.874] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.874] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.889] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=6818
[2018/03/29-12:40:05.890] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=6818 totalRecords=6818
[2018/03/29-12:40:05.891] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000014_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.914] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.917] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.923] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.923] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.938] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=8079
[2018/03/29-12:40:05.939] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=8079 totalRecords=8079
[2018/03/29-12:40:05.940] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000015_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:05.973] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:05.975] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:05.981] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:05.981] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:05.993] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=9219
[2018/03/29-12:40:05.994] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=9219 totalRecords=9219
[2018/03/29-12:40:05.996] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000016_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:06.024] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:06.026] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:06.032] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:06.033] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:06.044] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=10239
[2018/03/29-12:40:06.045] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=10239 totalRecords=10239
[2018/03/29-12:40:06.046] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000017_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:06.075] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:06.077] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:06.082] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:06.082] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:06.094] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=11223
[2018/03/29-12:40:06.095] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=11223 totalRecords=11223
[2018/03/29-12:40:06.096] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000018_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:06.125] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:06.127] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:06.133] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:06.133] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:06.145] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=12216
[2018/03/29-12:40:06.145] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=12216 totalRecords=12216
[2018/03/29-12:40:06.147] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000019_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:06.175] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:06.177] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:06.183] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:06.183] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:06.198] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=13202
[2018/03/29-12:40:06.199] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=13202 totalRecords=13202
[2018/03/29-12:40:06.200] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000020_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:06.222] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:06.224] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:06.230] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:06.230] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:06.286] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=27766
[2018/03/29-12:40:06.287] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=27766 totalRecords=27766
[2018/03/29-12:40:06.289] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000021_0 with ugi: dataiku (auth:SIMPLE)
7.604: [GC (Allocation Failure) [PSYoungGen: 326479K->5978K(425984K)] 347412K->26919K(1140736K), 0.0069500 secs] [Times: user=0.03 sys=0.01, real=0.00 secs] 
[2018/03/29-12:40:06.318] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:06.323] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:06.329] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:06.329] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:06.385] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=42062
[2018/03/29-12:40:06.386] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=42062 totalRecords=42062
[2018/03/29-12:40:06.389] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000022_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:06.411] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:06.413] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:06.419] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:06.420] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:06.476] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=55440
[2018/03/29-12:40:06.476] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=55440 totalRecords=55440
[2018/03/29-12:40:06.478] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000023_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:06.511] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:06.513] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:06.519] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:06.520] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:06.600] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=69514
[2018/03/29-12:40:06.600] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=69514 totalRecords=69514
[2018/03/29-12:40:06.602] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000024_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:06.632] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:06.634] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:06.640] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:06.640] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
8.277: [GC (Allocation Failure) [PSYoungGen: 415066K->10750K(430080K)] 436007K->328448K(1144832K), 0.0331384 secs] [Times: user=0.12 sys=0.12, real=0.03 secs] 
[2018/03/29-12:40:07.325] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:07.333] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
8.788: [GC (Allocation Failure) [PSYoungGen: 419838K->15927K(633856K)] 737536K->333633K(1348608K), 0.0089807 secs] [Times: user=0.03 sys=0.02, real=0.01 secs] 
9.473: [GC (Allocation Failure) [PSYoungGen: 630327K->15526K(634880K)] 948033K->333239K(1349632K), 0.0091818 secs] [Times: user=0.02 sys=0.02, real=0.01 secs] 
[2018/03/29-12:40:08.467] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=612714
[2018/03/29-12:40:08.468] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=612714 totalRecords=612714
[2018/03/29-12:40:08.469] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000025_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:08.488] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:08.490] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1231 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 1231
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1261 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 1 ms. row count = 1261
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1140 records.
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 1140
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1020 records.
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 1020
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 984 records.
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 2 ms. row count = 984
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 993 records.
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 3 ms. row count = 993
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 986 records.
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 4 ms. row count = 986
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 14564 records.
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 3 ms. row count = 14564
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 14296 records.
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 3 ms. row count = 14296
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 13378 records.
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 5 ms. row count = 13378
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 14074 records.
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 3 ms. row count = 14074
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 543200 records.
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 104 ms. row count = 543200
Mar 29, 2018 12:40:08 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
[2018/03/29-12:40:08.494] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:08.494] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
10.143: [GC (Allocation Failure) [PSYoungGen: 629926K->12480K(677376K)] 947639K->611478K(1392128K), 0.0330452 secs] [Times: user=0.13 sys=0.11, real=0.03 secs] 
10.176: [Full GC (Ergonomics) [PSYoungGen: 12480K->0K(677376K)] [ParOldGen: 598998K->60229K(1157632K)] 611478K->60229K(1835008K), [Metaspace: 50844K->50844K(1095680K)], 0.1378587 secs] [Times: user=0.65 sys=0.01, real=0.14 secs] 
10.964: [GC (Allocation Failure) [PSYoungGen: 656896K->9866K(677376K)] 717125K->70104K(1835008K), 0.0031874 secs] [Times: user=0.02 sys=0.01, real=0.00 secs] 
[2018/03/29-12:40:10.187] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=1133605
[2018/03/29-12:40:10.187] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=1133605 totalRecords=1133605
[2018/03/29-12:40:10.189] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000026_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:10.209] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:10.210] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:10.216] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:10.217] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
11.681: [GC (Allocation Failure) [PSYoungGen: 666762K->16288K(676864K)] 727000K->337422K(1834496K), 0.0123776 secs] [Times: user=0.08 sys=0.01, real=0.02 secs] 
12.364: [GC (Allocation Failure) [PSYoungGen: 673184K->20052K(677376K)] 994318K->341195K(1835008K), 0.0061026 secs] [Times: user=0.03 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:11.697] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=1625231
[2018/03/29-12:40:11.697] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=1625231 totalRecords=1625231
[2018/03/29-12:40:11.699] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000027_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:11.719] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:11.721] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:11.725] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:11.725] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
13.022: [GC (Allocation Failure) [PSYoungGen: 660964K->3139K(673280K)] 982106K->324290K(1830912K), 0.0025147 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:12.333] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:12.343] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
13.725: [GC (Allocation Failure) [PSYoungGen: 654915K->10119K(675328K)] 976066K->507907K(1832960K), 0.0119173 secs] [Times: user=0.05 sys=0.00, real=0.01 secs] 
14.381: [GC (Allocation Failure) [PSYoungGen: 661895K->19143K(672768K)] 1159683K->516931K(1830400K), 0.0062372 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:13.277] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=2148086
[2018/03/29-12:40:13.278] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=2148086 totalRecords=2148086
[2018/03/29-12:40:13.279] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000028_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:13.301] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:13.303] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:13.308] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:13.309] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
15.178: [GC (Allocation Failure) --[PSYoungGen: 668871K->668871K(672768K)] 1166659K->1953678K(2071040K), 0.2301050 secs] [Times: user=0.57 sys=0.21, real=0.23 secs] 
15.409: [Full GC (Ergonomics) [PSYoungGen: 668871K->0K(672768K)] [ParOldGen: 1284807K->155232K(1398272K)] 1953678K->155232K(2071040K), [Metaspace: 50958K->50958K(1095680K)], 0.0799005 secs] [Times: user=0.27 sys=0.01, real=0.08 secs] 
16.129: [GC (Allocation Failure) [PSYoungGen: 649728K->7721K(674304K)] 804960K->162953K(2072576K), 0.0023179 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
16.765: [GC (Allocation Failure) [PSYoungGen: 657449K->9005K(672768K)] 812681K->164238K(2071040K), 0.0021528 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
17.462: [GC (Allocation Failure) [PSYoungGen: 659245K->6794K(673792K)] 814478K->162027K(2072064K), 0.0021005 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
18.073: [GC (Allocation Failure) [PSYoungGen: 657034K->8749K(673792K)] 812267K->163982K(2072064K), 0.0020566 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:17.343] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:17.351] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
18.686: [GC (Allocation Failure) [PSYoungGen: 661037K->5616K(674816K)] 816270K->160848K(2073088K), 0.0020707 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
19.301: [GC (Allocation Failure) [PSYoungGen: 657904K->10889K(674304K)] 813136K->166121K(2072576K), 0.0020656 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:18.308] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=3766676
[2018/03/29-12:40:18.308] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:18.314] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:18.315] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
20.002: [GC (Allocation Failure) [PSYoungGen: 664713K->9197K(675328K)] 819945K->554706K(2073600K), 0.0156531 secs] [Times: user=0.11 sys=0.00, real=0.01 secs] 
20.647: [GC (Allocation Failure) [PSYoungGen: 663021K->15911K(676352K)] 1208530K->561420K(2074624K), 0.0052035 secs] [Times: user=0.03 sys=0.00, real=0.00 secs] 
21.348: [GC (Allocation Failure) [PSYoungGen: 671783K->13245K(677376K)] 1217292K->558754K(2075648K), 0.0057120 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:20.346] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=4447033
[2018/03/29-12:40:20.346] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=4447033 totalRecords=4447033
[2018/03/29-12:40:20.347] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000029_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:20.368] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:20.369] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:20.374] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:20.374] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
22.123: [GC (Allocation Failure) --[PSYoungGen: 669117K->669117K(677376K)] 1214626K->2004309K(2075648K), 0.1768413 secs] [Times: user=0.40 sys=0.01, real=0.17 secs] 
22.300: [Full GC (Ergonomics) [PSYoungGen: 669117K->0K(677376K)] [ParOldGen: 1335191K->156051K(1398272K)] 2004309K->156051K(2075648K), [Metaspace: 50990K->50990K(1095680K)], 0.0578453 secs] [Times: user=0.22 sys=0.00, real=0.06 secs] 
23.060: [GC (Allocation Failure) [PSYoungGen: 655872K->6702K(676352K)] 811923K->162754K(2074624K), 0.0021517 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:22.351] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:22.361] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
23.678: [GC (Allocation Failure) [PSYoungGen: 662574K->12741K(676864K)] 818626K->168793K(2075136K), 0.0024911 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
24.295: [GC (Allocation Failure) [PSYoungGen: 668613K->9849K(675840K)] 824665K->165901K(2074112K), 0.0024987 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
24.915: [GC (Allocation Failure) [PSYoungGen: 666745K->5488K(676864K)] 822797K->161540K(2075136K), 0.0022470 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
25.596: [GC (Allocation Failure) [PSYoungGen: 662384K->7601K(677888K)] 818436K->163652K(2076160K), 0.0019887 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
26.215: [GC (Allocation Failure) [PSYoungGen: 666545K->8856K(678400K)] 822596K->164908K(2076672K), 0.0024460 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:25.305] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=6069868
[2018/03/29-12:40:25.305] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:25.311] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:25.311] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
26.910: [GC (Allocation Failure) [PSYoungGen: 667800K->11333K(678400K)] 823852K->502764K(2076672K), 0.0132210 secs] [Times: user=0.10 sys=0.00, real=0.02 secs] 
27.580: [GC (Allocation Failure) [PSYoungGen: 671813K->13067K(678912K)] 1163244K->504497K(2077184K), 0.0054043 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
28.230: [GC (Allocation Failure) [PSYoungGen: 673547K->13325K(679936K)] 1164977K->504756K(2078208K), 0.0046553 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:27.081] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=6671608
[2018/03/29-12:40:27.081] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=6671608 totalRecords=6671608
[2018/03/29-12:40:27.082] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000030_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:27.103] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:27.105] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:27.110] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:27.111] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:40:27.361] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:27.369] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
29.621: [GC (Allocation Failure) --[PSYoungGen: 674317K->674317K(679936K)] 1165748K->1954978K(2078208K), 0.1723858 secs] [Times: user=0.38 sys=0.00, real=0.18 secs] 
29.794: [Full GC (Ergonomics) [PSYoungGen: 674317K->0K(679936K)] [ParOldGen: 1280660K->156926K(1398272K)] 1954978K->156926K(2078208K), [Metaspace: 51021K->51021K(1095680K)], 0.0650447 secs] [Times: user=0.25 sys=0.00, real=0.06 secs] 
30.542: [GC (Allocation Failure) [PSYoungGen: 660992K->8581K(669696K)] 817918K->165507K(2067968K), 0.0025137 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
31.225: [GC (Allocation Failure) [PSYoungGen: 669573K->7524K(679424K)] 826499K->164450K(2077696K), 0.0022181 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
31.909: [GC (Allocation Failure) [PSYoungGen: 668516K->10765K(679424K)] 825442K->167691K(2077696K), 0.0020857 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
32.569: [GC (Allocation Failure) [PSYoungGen: 671757K->7568K(679936K)] 828683K->164494K(2078208K), 0.0025771 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
33.226: [GC (Allocation Failure) [PSYoungGen: 670096K->7600K(679936K)] 827022K->164526K(2078208K), 0.0023222 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:32.369] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:32.378] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
33.881: [GC (Allocation Failure) [PSYoungGen: 670128K->12783K(681472K)] 827054K->169709K(2079744K), 0.0021697 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:32.797] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=8294443
[2018/03/29-12:40:32.797] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:32.803] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:32.803] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
34.597: [GC (Allocation Failure) [PSYoungGen: 676847K->10603K(674816K)] 833773K->390935K(2073088K), 0.0122151 secs] [Times: user=0.07 sys=0.00, real=0.01 secs] 
35.277: [GC (Allocation Failure) [PSYoungGen: 674667K->16889K(677888K)] 1054999K->397741K(2076160K), 0.0057776 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:34.233] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=8772251
[2018/03/29-12:40:34.233] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=8772251 totalRecords=8772251
[2018/03/29-12:40:34.234] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000031_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:34.254] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:34.255] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:34.261] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:34.261] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
36.092: [GC (Allocation Failure) --[PSYoungGen: 677881K->677881K(677888K)] 1058733K->1974583K(2076160K), 0.1729737 secs] [Times: user=0.39 sys=0.00, real=0.18 secs] 
36.265: [Full GC (Ergonomics) [PSYoungGen: 677881K->0K(677888K)] [ParOldGen: 1296702K->155035K(1398272K)] 1974583K->155035K(2076160K), [Metaspace: 51037K->51037K(1095680K)], 0.0672554 secs] [Times: user=0.24 sys=0.00, real=0.06 secs] 
37.104: [GC (Allocation Failure) [PSYoungGen: 660992K->12951K(679936K)] 816027K->167987K(2078208K), 0.0020762 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
37.764: [GC (Allocation Failure) [PSYoungGen: 673943K->12950K(679936K)] 828979K->167986K(2078208K), 0.0022353 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
38.422: [GC (Allocation Failure) [PSYoungGen: 673942K->11812K(673280K)] 828978K->166848K(2071552K), 0.0021263 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:37.379] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:37.388] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
39.077: [GC (Allocation Failure) [PSYoungGen: 672804K->8560K(679424K)] 827840K->163596K(2077696K), 0.0028421 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
39.733: [GC (Allocation Failure) [PSYoungGen: 669552K->11728K(679424K)] 824588K->166764K(2077696K), 0.0022224 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
40.388: [GC (Allocation Failure) [PSYoungGen: 672720K->10672K(679936K)] 827756K->165732K(2078208K), 0.0024539 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:39.355] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=10376817
[2018/03/29-12:40:39.355] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:39.361] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:39.361] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
41.162: [GC (Allocation Failure) [PSYoungGen: 673200K->12307K(679936K)] 828260K->460564K(2078208K), 0.0132685 secs] [Times: user=0.08 sys=0.00, real=0.02 secs] 
41.845: [GC (Allocation Failure) [PSYoungGen: 674835K->14791K(679936K)] 1123092K->463049K(2078208K), 0.0059224 secs] [Times: user=0.03 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:41.208] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=10978347
[2018/03/29-12:40:41.208] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=10978347 totalRecords=10978347
[2018/03/29-12:40:41.210] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000032_0 with ugi: dataiku (auth:SIMPLE)
42.508: [GC (Allocation Failure) [PSYoungGen: 677831K->2376K(665600K)] 1126089K->450657K(2063872K), 0.0023681 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:41.239] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:41.241] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:41.246] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:41.247] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
43.334: [GC (Allocation Failure) --[PSYoungGen: 665416K->665416K(665600K)] 1113697K->2032331K(2063872K), 0.1657161 secs] [Times: user=0.37 sys=0.01, real=0.16 secs] 
43.500: [Full GC (Ergonomics) [PSYoungGen: 665416K->0K(665600K)] [ParOldGen: 1366915K->157182K(1398272K)] 2032331K->157182K(2063872K), [Metaspace: 51062K->51062K(1095680K)], 0.0757653 secs] [Times: user=0.25 sys=0.00, real=0.08 secs] 
[2018/03/29-12:40:42.388] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:42.396] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
44.240: [GC (Allocation Failure) [PSYoungGen: 663040K->9797K(680960K)] 820222K->166979K(2079232K), 0.0020177 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
44.890: [GC (Allocation Failure) [PSYoungGen: 671813K->10682K(672768K)] 828995K->167865K(2071040K), 0.0020919 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
45.542: [GC (Allocation Failure) [PSYoungGen: 672698K->11706K(679424K)] 829881K->168888K(2077696K), 0.0019235 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
46.192: [GC (Allocation Failure) [PSYoungGen: 673722K->5839K(679424K)] 830904K->163045K(2077696K), 0.0019443 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
46.844: [GC (Allocation Failure) [PSYoungGen: 667367K->8822K(680448K)] 824573K->166036K(2078720K), 0.0019851 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
47.495: [GC (Allocation Failure) [PSYoungGen: 672886K->10678K(680960K)] 830100K->167900K(2079232K), 0.0022205 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:46.340] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=12631128
[2018/03/29-12:40:46.340] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:46.346] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:46.346] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
48.196: [GC (Allocation Failure) [PSYoungGen: 674742K->13430K(681472K)] 831964K->341419K(2079744K), 0.0098848 secs] [Times: user=0.07 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:47.396] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:47.404] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
48.858: [GC (Allocation Failure) [PSYoungGen: 678518K->9589K(681984K)] 1006507K->348354K(2080256K), 0.0052844 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:47.636] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=13075981
[2018/03/29-12:40:47.636] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=13075981 totalRecords=13075981
[2018/03/29-12:40:47.638] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000033_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:47.660] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:47.661] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
Mar 29, 2018 12:40:08 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:08 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 520891 records.
Mar 29, 2018 12:40:08 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:08 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 72 ms. row count = 520891
Mar 29, 2018 12:40:10 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:10 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:10 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 491626 records.
Mar 29, 2018 12:40:10 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:10 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 85 ms. row count = 491626
Mar 29, 2018 12:40:11 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:11 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:11 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 522855 records.
Mar 29, 2018 12:40:11 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:11 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 71 ms. row count = 522855
Mar 29, 2018 12:40:13 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:13 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:13 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1618590 records.
Mar 29, 2018 12:40:13 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:13 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 241 ms. row count = 1618590
Mar 29, 2018 12:40:18 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:18 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 680357 records.
Mar 29, 2018 12:40:18 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:18 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 112 ms. row count = 680357
Mar 29, 2018 12:40:20 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:20 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:20 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1622835 records.
Mar 29, 2018 12:40:20 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:20 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 239 ms. row count = 1622835
Mar 29, 2018 12:40:25 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:25 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 601740 records.
Mar 29, 2018 12:40:25 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:25 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 83 ms. row count = 601740
Mar 29, 2018 12:40:27 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:27 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:27 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1622835 records.
Mar 29, 2018 12:40:27 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:27 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 820 ms. row count = 1622835
Mar 29, 2018 12:40:32 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:32 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 477808 records.
Mar 29, 2018 12:40:32 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:32 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 62 ms. row count = 477808
Mar 29, 2018 12:40:34 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:34 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:34 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1604566 records.
Mar 29, 2018 12:40:34 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:34 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 243 ms. row count = 1604566
Mar 29, 2018 12:40:39 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:39 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 601530 records.
Mar 29, 2018 12:40:39 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:39 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 129 ms. row count = 601530
Mar 29, 2018 12:40:41 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:41 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:41 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1652781 records.
Mar 29, 2018 12:40:41 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:41 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 252 ms. row count = 1652781
Mar 29, 2018 12:40:46 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:46 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 444853 records.
Mar 29, 2018 12:40:46 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:46 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 54 ms. row count = 444853
Mar 29, 2018 12:40:47 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
[2018/03/29-12:40:47.667] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:47.667] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
49.706: [GC (Allocation Failure) [PSYoungGen: 674677K->11124K(680960K)] 1013442K->1397513K(2079232K), 0.0462387 secs] [Times: user=0.34 sys=0.01, real=0.04 secs] 
49.752: [Full GC (Ergonomics) [PSYoungGen: 11124K->0K(680960K)] [ParOldGen: 1386388K->155703K(1398272K)] 1397513K->155703K(2079232K), [Metaspace: 51083K->51083K(1095680K)], 0.0664855 secs] [Times: user=0.28 sys=0.00, real=0.07 secs] 
50.461: [GC (Allocation Failure) [PSYoungGen: 665088K->13001K(681472K)] 820791K->168705K(2079744K), 0.0020009 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
51.113: [GC (Allocation Failure) [PSYoungGen: 678089K->6556K(681984K)] 833793K->162275K(2080256K), 0.0019333 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
51.763: [GC (Allocation Failure) [PSYoungGen: 671644K->12965K(678400K)] 827363K->168693K(2076672K), 0.0022198 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
52.415: [GC (Allocation Failure) [PSYoungGen: 678053K->10688K(682496K)] 833781K->166416K(2080768K), 0.0021583 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
53.070: [GC (Allocation Failure) [PSYoungGen: 675776K->10883K(681472K)] 831504K->166611K(2079744K), 0.0021134 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:40:52.404] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
53.702: [GC (Allocation Failure) [PSYoungGen: 675971K->9689K(681984K)] 831699K->165417K(2080256K), 0.0023808 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:52.413] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
[2018/03/29-12:40:52.607] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=14736081
[2018/03/29-12:40:52.607] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:52.613] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:52.613] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
54.402: [GC (Allocation Failure) [PSYoungGen: 675289K->12357K(681472K)] 831017K->285286K(2079744K), 0.0079343 secs] [Times: user=0.04 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:53.725] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=15114781
[2018/03/29-12:40:53.725] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=15114781 totalRecords=15114781
[2018/03/29-12:40:53.727] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000034_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:53.755] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:53.757] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:53.761] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:53.761] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
55.058: [GC (Allocation Failure) [PSYoungGen: 638976K->6820K(682496K)] 911905K->279749K(2080768K), 0.0023191 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
55.850: [GC (Allocation Failure) [PSYoungGen: 673444K->11741K(682496K)] 946373K->1332103K(2080768K), 0.0502024 secs] [Times: user=0.36 sys=0.00, real=0.05 secs] 
55.900: [Full GC (Ergonomics) [PSYoungGen: 11741K->0K(682496K)] [ParOldGen: 1320362K->156585K(1398272K)] 1332103K->156585K(2080768K), [Metaspace: 51130K->51130K(1095680K)], 0.0632947 secs] [Times: user=0.25 sys=0.00, real=0.07 secs] 
56.613: [GC (Allocation Failure) [PSYoungGen: 666624K->9962K(683008K)] 823209K->166548K(2081280K), 0.0019647 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
57.265: [GC (Allocation Failure) [PSYoungGen: 677098K->9797K(677376K)] 833684K->166383K(2075648K), 0.0022692 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
57.903: [GC (Allocation Failure) [PSYoungGen: 676933K->8602K(683008K)] 833519K->165188K(2081280K), 0.0022919 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
58.563: [GC (Allocation Failure) [PSYoungGen: 676250K->9845K(682496K)] 832836K->166430K(2080768K), 0.0020777 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:57.414] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:40:57.422] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
59.222: [GC (Allocation Failure) [PSYoungGen: 677493K->7641K(683520K)] 834078K->164227K(2081792K), 0.0023564 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
59.880: [GC (Allocation Failure) [PSYoungGen: 676313K->8363K(683520K)] 832899K->164948K(2081792K), 0.0021869 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
60.583: [GC (Allocation Failure) [PSYoungGen: 677035K->14315K(612864K)] 833620K->264082K(2011136K), 0.0073238 secs] [Times: user=0.05 sys=0.00, real=0.00 secs] 
[2018/03/29-12:40:59.448] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=17027979
[2018/03/29-12:40:59.449] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=17027979 totalRecords=17027979
[2018/03/29-12:40:59.450] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000035_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:40:59.470] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:40:59.471] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:40:59.475] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:40:59.475] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
61.382: [GC (Allocation Failure) [PSYoungGen: 612843K->17501K(648704K)] 862610K->1317223K(2046976K), 0.0506923 secs] [Times: user=0.34 sys=0.01, real=0.06 secs] 
61.432: [Full GC (Ergonomics) [PSYoungGen: 17501K->0K(648704K)] [ParOldGen: 1299721K->155867K(1398272K)] 1317223K->155867K(2046976K), [Metaspace: 51141K->51141K(1095680K)], 0.0660601 secs] [Times: user=0.28 sys=0.00, real=0.06 secs] 
62.108: [GC (Allocation Failure) [PSYoungGen: 598528K->7514K(644096K)] 754395K->163382K(2042368K), 0.0031195 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
62.700: [GC (Allocation Failure) [PSYoungGen: 608602K->8634K(647680K)] 764470K->164502K(2045952K), 0.0023872 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
63.291: [GC (Allocation Failure) [PSYoungGen: 609722K->11706K(647168K)] 765590K->167574K(2045440K), 0.0021485 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:41:02.422] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:02.431] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
63.882: [GC (Allocation Failure) [PSYoungGen: 618426K->11822K(650240K)] 774294K->167689K(2048512K), 0.0027055 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
64.501: [GC (Allocation Failure) [PSYoungGen: 618542K->11976K(649728K)] 774409K->167843K(2048000K), 0.0023990 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
65.099: [GC (Allocation Failure) [PSYoungGen: 625352K->9743K(653312K)] 781219K->165611K(2051584K), 0.0022167 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
65.710: [GC (Allocation Failure) [PSYoungGen: 623119K->10947K(654336K)] 778987K->166814K(2052608K), 0.0025242 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:41:04.514] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=18680760
[2018/03/29-12:41:04.514] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:04.525] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:04.525] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
66.444: [GC (Allocation Failure) [PSYoungGen: 631491K->27783K(657408K)] 787358K->238725K(2055680K), 0.0085672 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
[2018/03/29-12:41:05.675] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=19048204
[2018/03/29-12:41:05.675] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=19048204 totalRecords=19048204
[2018/03/29-12:41:05.677] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000036_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:41:05.696] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:41:05.700] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:05.707] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:05.707] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
67.005: [GC (Allocation Failure) [PSYoungGen: 550956K->4506K(659456K)] 761898K->215448K(2057728K), 0.0030749 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
67.719: [GC (Allocation Failure) [PSYoungGen: 624538K->11085K(631296K)] 835480K->1271459K(2029568K), 0.0581655 secs] [Times: user=0.35 sys=0.00, real=0.06 secs] 
67.777: [Full GC (Ergonomics) [PSYoungGen: 11085K->0K(631296K)] [ParOldGen: 1260374K->156873K(1398272K)] 1271459K->156873K(2029568K), [Metaspace: 51154K->51154K(1095680K)], 0.0741328 secs] [Times: user=0.26 sys=0.00, real=0.07 secs] 
68.567: [GC (Allocation Failure) [PSYoungGen: 620032K->7819K(658432K)] 776905K->164692K(2056704K), 0.0021654 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:41:07.432] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:07.440] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
69.156: [GC (Allocation Failure) [PSYoungGen: 628875K->12772K(657408K)] 785748K->169646K(2055680K), 0.0023882 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
69.748: [GC (Allocation Failure) [PSYoungGen: 633828K->9796K(660992K)] 790702K->166669K(2059264K), 0.0021558 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
70.392: [GC (Allocation Failure) [PSYoungGen: 636484K->9682K(659456K)] 793357K->166555K(2057728K), 0.0021566 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
71.003: [GC (Allocation Failure) [PSYoungGen: 636370K->7600K(664576K)] 793243K->164473K(2062848K), 0.0021364 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
71.635: [GC (Allocation Failure) [PSYoungGen: 640432K->6574K(663552K)] 797305K->163447K(2061824K), 0.0020937 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[2018/03/29-12:41:10.754] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=20708304
[2018/03/29-12:41:10.754] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:10.760] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:10.760] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
72.481: [GC (Allocation Failure) [PSYoungGen: 639406K->12546K(666624K)] 796279K->1219113K(2064896K), 0.0426839 secs] [Times: user=0.30 sys=0.00, real=0.05 secs] 
72.524: [Full GC (Ergonomics) [PSYoungGen: 12546K->0K(666624K)] [ParOldGen: 1206567K->155886K(1398272K)] 1219113K->155886K(2064896K), [Metaspace: 51172K->51172K(1095680K)], 0.0733661 secs] [Times: user=0.31 sys=0.00, real=0.07 secs] 
73.240: [GC (Allocation Failure) [PSYoungGen: 637952K->3570K(666112K)] 793838K->159456K(2064384K), 0.0021747 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
73.242: [Full GC (Ergonomics) [PSYoungGen: 3570K->0K(666112K)] [ParOldGen: 155886K->157610K(1398272K)] 159456K->157610K(2064384K), [Metaspace: 51172K->51172K(1095680K)], 0.1243145 secs] [Times: user=0.62 sys=0.01, real=0.12 secs] 
[2018/03/29-12:41:12.441] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:12.450] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
73.972: [GC (Allocation Failure) [PSYoungGen: 637952K->8749K(668160K)] 795562K->166360K(2066432K), 0.0021374 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
74.610: [GC (Allocation Failure) [PSYoungGen: 651309K->6818K(669184K)] 808920K->164429K(2067456K), 0.0021458 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
75.221: [GC (Allocation Failure) [PSYoungGen: 649378K->12144K(669696K)] 806989K->169755K(2067968K), 0.0021978 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
75.836: [GC (Allocation Failure) [PSYoungGen: 658288K->8707K(671232K)] 815899K->166318K(2069504K), 0.0036678 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
76.454: [GC (Allocation Failure) [PSYoungGen: 654851K->7569K(671232K)] 812462K->165180K(2069504K), 0.0025841 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
77.077: [GC (Allocation Failure) [PSYoungGen: 657297K->3141K(672768K)] 814908K->160752K(2071040K), 0.0025347 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[2018/03/29-12:41:15.849] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=22368404
[2018/03/29-12:41:15.849] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:15.860] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:15.861] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
77.855: [GC (Allocation Failure) [PSYoungGen: 652869K->9731K(673792K)] 810480K->1216847K(2072064K), 0.0490153 secs] [Times: user=0.32 sys=0.00, real=0.05 secs] 
77.904: [Full GC (Ergonomics) [PSYoungGen: 9731K->0K(673792K)] [ParOldGen: 1207116K->155685K(1398272K)] 1216847K->155685K(2072064K), [Metaspace: 51195K->51195K(1095680K)], 0.0842132 secs] [Times: user=0.41 sys=0.00, real=0.08 secs] 
78.631: [GC (Allocation Failure) [PSYoungGen: 652800K->5540K(674816K)] 808485K->161225K(2073088K), 0.0022761 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
78.634: [Full GC (Ergonomics) [PSYoungGen: 5540K->0K(674816K)] [ParOldGen: 155685K->158522K(1398272K)] 161225K->158522K(2073088K), [Metaspace: 51195K->51195K(1095680K)], 0.0627253 secs] [Times: user=0.22 sys=0.00, real=0.06 secs] 
[2018/03/29-12:41:17.450] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
79.351: [GC (Allocation Failure) [PSYoungGen: 652800K->5573K(674304K)] 811322K->164096K(2072576K), 0.0020571 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
79.353: [Full GC (Ergonomics) [PSYoungGen: 5573K->0K(674304K)] [ParOldGen: 158522K->158534K(1398272K)] 164096K->158534K(2072576K), [Metaspace: 51195K->51195K(1095680K)], 0.0479669 secs] [Times: user=0.19 sys=0.00, real=0.04 secs] 
[2018/03/29-12:41:18.383] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
80.058: [GC (Allocation Failure) [PSYoungGen: 655360K->10736K(675840K)] 813894K->169271K(2074112K), 0.0024869 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
80.061: [Full GC (Ergonomics) [PSYoungGen: 10736K->0K(675840K)] [ParOldGen: 158534K->158534K(1398272K)] 169271K->158534K(2074112K), [Metaspace: 51195K->51195K(1095680K)], 0.0448845 secs] [Times: user=0.16 sys=0.00, real=0.05 secs] 
80.754: [GC (Allocation Failure) [PSYoungGen: 655360K->7801K(676352K)] 813894K->166336K(2074624K), 0.0021909 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
80.757: [Full GC (Ergonomics) [PSYoungGen: 7801K->0K(676352K)] [ParOldGen: 158534K->158534K(1398272K)] 166336K->158534K(2074624K), [Metaspace: 51195K->51195K(1095680K)], 0.0470765 secs] [Times: user=0.15 sys=0.00, real=0.05 secs] 
81.495: [GC (Allocation Failure) [PSYoungGen: 657920K->11821K(677376K)] 816454K->170356K(2075648K), 0.0021609 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
81.498: [Full GC (Ergonomics) [PSYoungGen: 11821K->0K(677376K)] [ParOldGen: 158534K->158489K(1398272K)] 170356K->158489K(2075648K), [Metaspace: 51195K->51195K(1095680K)], 0.0505859 secs] [Times: user=0.20 sys=0.00, real=0.05 secs] 
82.169: [GC (Allocation Failure) [PSYoungGen: 657920K->9649K(677376K)] 816409K->168139K(2075648K), 0.0021259 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
82.171: [Full GC (Ergonomics) [PSYoungGen: 9649K->0K(677376K)] [ParOldGen: 158489K->158491K(1398272K)] 168139K->158491K(2075648K), [Metaspace: 51195K->51195K(1095680K)], 0.0434273 secs] [Times: user=0.15 sys=0.00, real=0.05 secs] 
[2018/03/29-12:41:21.177] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=24028504
[2018/03/29-12:41:21.178] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:21.188] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:21.188] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
83.094: [GC (Allocation Failure) [PSYoungGen: 659968K->11657K(678400K)] 818459K->1199151K(2076672K), 0.0649071 secs] [Times: user=0.41 sys=0.00, real=0.06 secs] 
83.159: [Full GC (Ergonomics) [PSYoungGen: 11657K->0K(678400K)] [ParOldGen: 1187494K->153087K(1398272K)] 1199151K->153087K(2076672K), [Metaspace: 51198K->51198K(1095680K)], 0.0658181 secs] [Times: user=0.24 sys=0.00, real=0.07 secs] 
83.893: [GC (Allocation Failure) [PSYoungGen: 659968K->12832K(679424K)] 813055K->165920K(2077696K), 0.0021730 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
83.895: [Full GC (Ergonomics) [PSYoungGen: 12832K->0K(679424K)] [ParOldGen: 153087K->155940K(1398272K)] 165920K->155940K(2077696K), [Metaspace: 51198K->51198K(1095680K)], 0.0776599 secs] [Times: user=0.40 sys=0.01, real=0.08 secs] 
84.608: [GC (Allocation Failure) [PSYoungGen: 660992K->9773K(671232K)] 816932K->165713K(2069504K), 0.0019959 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
84.610: [Full GC (Ergonomics) [PSYoungGen: 9773K->0K(671232K)] [ParOldGen: 155940K->155930K(1398272K)] 165713K->155930K(2069504K), [Metaspace: 51198K->51198K(1095680K)], 0.1354397 secs] [Times: user=0.70 sys=0.00, real=0.14 secs] 
[2018/03/29-12:41:23.452] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:23.460] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
85.408: [GC (Allocation Failure) [PSYoungGen: 660992K->9769K(679936K)] 816922K->165708K(2078208K), 0.0022349 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
85.410: [Full GC (Ergonomics) [PSYoungGen: 9769K->0K(679936K)] [ParOldGen: 155938K->155932K(1398272K)] 165708K->155932K(2078208K), [Metaspace: 51200K->51200K(1095680K)], 0.0425782 secs] [Times: user=0.14 sys=0.01, real=0.05 secs] 
86.104: [GC (Allocation Failure) [PSYoungGen: 662016K->10067K(679424K)] 817948K->166000K(2077696K), 0.0020554 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
86.106: [Full GC (Ergonomics) [PSYoungGen: 10067K->0K(679424K)] [ParOldGen: 155932K->155927K(1398272K)] 166000K->155927K(2077696K), [Metaspace: 51200K->51200K(1095680K)], 0.0511956 secs] [Times: user=0.19 sys=0.00, real=0.05 secs] 
86.807: [GC (Allocation Failure) [PSYoungGen: 662016K->5486K(680448K)] 817943K->161414K(2078720K), 0.0040969 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
86.811: [Full GC (Ergonomics) [PSYoungGen: 5486K->0K(680448K)] [ParOldGen: 155927K->155918K(1398272K)] 161414K->155918K(2078720K), [Metaspace: 51201K->51201K(1095680K)], 0.0508181 secs] [Times: user=0.14 sys=0.00, real=0.05 secs] 
87.519: [GC (Allocation Failure) [PSYoungGen: 663552K->6672K(680448K)] 819470K->162591K(2078720K), 0.0020481 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
87.521: [Full GC (Ergonomics) [PSYoungGen: 6672K->0K(680448K)] [ParOldGen: 155918K->155889K(1398272K)] 162591K->155889K(2078720K), [Metaspace: 51201K->51201K(1095680K)], 0.0434194 secs] [Times: user=0.15 sys=0.00, real=0.05 secs] 
[2018/03/29-12:41:26.608] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=25660780
[2018/03/29-12:41:26.608] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=25660780 totalRecords=25660780
[2018/03/29-12:41:26.614] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000037_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:41:26.633] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:41:26.636] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:26.641] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:26.641] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
88.365: [GC (Allocation Failure) [PSYoungGen: 663552K->11348K(681472K)] 819441K->1216729K(2079744K), 0.0456608 secs] [Times: user=0.33 sys=0.00, real=0.04 secs] 
88.411: [Full GC (Ergonomics) [PSYoungGen: 11348K->0K(681472K)] [ParOldGen: 1205380K->155737K(1398272K)] 1216729K->155737K(2079744K), [Metaspace: 51214K->51214K(1095680K)], 0.0660368 secs] [Times: user=0.24 sys=0.00, real=0.07 secs] 
89.158: [GC (Allocation Failure) [PSYoungGen: 665088K->10691K(681472K)] 820825K->166429K(2079744K), 0.0020956 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
89.160: [Full GC (Ergonomics) [PSYoungGen: 10691K->0K(681472K)] [ParOldGen: 155737K->158548K(1398272K)] 166429K->158548K(2079744K), [Metaspace: 51214K->51214K(1095680K)], 0.0643922 secs] [Times: user=0.29 sys=0.00, real=0.07 secs] 
[2018/03/29-12:41:28.461] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:28.469] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
89.885: [GC (Allocation Failure) [PSYoungGen: 665088K->9637K(681472K)] 823636K->168186K(2079744K), 0.0021301 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
89.888: [Full GC (Ergonomics) [PSYoungGen: 9637K->0K(681472K)] [ParOldGen: 158548K->158554K(1398272K)] 168186K->158554K(2079744K), [Metaspace: 51214K->51214K(1095680K)], 0.0462295 secs] [Times: user=0.16 sys=0.00, real=0.05 secs] 
90.591: [GC (Allocation Failure) [PSYoungGen: 666112K->6753K(681984K)] 824666K->165307K(2080256K), 0.0021163 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
90.593: [Full GC (Ergonomics) [PSYoungGen: 6753K->0K(681984K)] [ParOldGen: 158554K->158562K(1398272K)] 165307K->158562K(2080256K), [Metaspace: 51214K->51214K(1095680K)], 0.0466494 secs] [Times: user=0.14 sys=0.00, real=0.04 secs] 
91.306: [GC (Allocation Failure) [PSYoungGen: 666112K->10673K(681984K)] 824674K->169236K(2080256K), 0.0023220 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
91.308: [Full GC (Ergonomics) [PSYoungGen: 10673K->0K(681984K)] [ParOldGen: 158562K->158546K(1398272K)] 169236K->158546K(2080256K), [Metaspace: 51214K->51214K(1095680K)], 0.0539597 secs] [Times: user=0.20 sys=0.00, real=0.06 secs] 
92.038: [GC (Allocation Failure) [PSYoungGen: 667136K->6963K(682496K)] 825682K->165509K(2080768K), 0.0022093 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
92.040: [Full GC (Ergonomics) [PSYoungGen: 6963K->0K(682496K)] [ParOldGen: 158546K->158546K(1398272K)] 165509K->158546K(2080768K), [Metaspace: 51214K->51214K(1095680K)], 0.0451579 secs] [Times: user=0.12 sys=0.00, real=0.05 secs] 
92.747: [GC (Allocation Failure) [PSYoungGen: 667136K->13745K(681472K)] 825682K->172291K(2079744K), 0.0027196 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
92.750: [Full GC (Ergonomics) [PSYoungGen: 13745K->0K(681472K)] [ParOldGen: 158546K->158506K(1398272K)] 172291K->158506K(2079744K), [Metaspace: 51214K->51214K(1095680K)], 0.0581265 secs] [Times: user=0.25 sys=0.00, real=0.06 secs] 
[2018/03/29-12:41:31.975] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=27320880
[2018/03/29-12:41:31.975] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:31.981] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:31.982] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
93.610: [GC (Allocation Failure) [PSYoungGen: 666112K->16359K(682496K)] 824618K->1229147K(2080768K), 0.0333976 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] 
93.643: [Full GC (Ergonomics) [PSYoungGen: 16359K->0K(682496K)] [ParOldGen: 1212787K->155447K(1398272K)] 1229147K->155447K(2080768K), [Metaspace: 51218K->51218K(1095680K)], 0.0621726 secs] [Times: user=0.26 sys=0.00, real=0.06 secs] 
94.500: [GC (Allocation Failure) [PSYoungGen: 666112K->5865K(249344K)] 821559K->161312K(1647616K), 0.0019830 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
94.502: [Full GC (Ergonomics) [PSYoungGen: 5865K->0K(249344K)] [ParOldGen: 155447K->157406K(1398272K)] 161312K->157406K(1647616K), [Metaspace: 51218K->51218K(1095680K)], 0.0416171 secs] [Times: user=0.15 sys=0.00, real=0.05 secs] 
[2018/03/29-12:41:33.470] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:33.479] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
94.774: [GC (Allocation Failure) [PSYoungGen: 232960K->3305K(465920K)] 390366K->160711K(1864192K), 0.0024553 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
94.777: [Full GC (Ergonomics) [PSYoungGen: 3305K->0K(465920K)] [ParOldGen: 157406K->158324K(1398272K)] 160711K->158324K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0476323 secs] [Times: user=0.17 sys=0.00, real=0.05 secs] 
95.057: [GC (Allocation Failure) [PSYoungGen: 232960K->7557K(465920K)] 391284K->165882K(1864192K), 0.0020327 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
95.059: [Full GC (Ergonomics) [PSYoungGen: 7557K->0K(465920K)] [ParOldGen: 158324K->158323K(1398272K)] 165882K->158323K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0418242 secs] [Times: user=0.16 sys=0.00, real=0.04 secs] 
95.332: [GC (Allocation Failure) [PSYoungGen: 232960K->9682K(465920K)] 391283K->168005K(1864192K), 0.0022032 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
95.335: [Full GC (Ergonomics) [PSYoungGen: 9682K->0K(465920K)] [ParOldGen: 158323K->158330K(1398272K)] 168005K->158330K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0406874 secs] [Times: user=0.14 sys=0.00, real=0.04 secs] 
95.609: [GC (Allocation Failure) [PSYoungGen: 232960K->7657K(465920K)] 391290K->165987K(1864192K), 0.0020417 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
95.611: [Full GC (Ergonomics) [PSYoungGen: 7657K->0K(465920K)] [ParOldGen: 158330K->158318K(1398272K)] 165987K->158318K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0444605 secs] [Times: user=0.17 sys=0.00, real=0.05 secs] 
95.888: [GC (Allocation Failure) [PSYoungGen: 232960K->8468K(465920K)] 391278K->166787K(1864192K), 0.0020477 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
95.890: [Full GC (Ergonomics) [PSYoungGen: 8468K->0K(465920K)] [ParOldGen: 158318K->158310K(1398272K)] 166787K->158310K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0431694 secs] [Times: user=0.14 sys=0.00, real=0.05 secs] 
96.162: [GC (Allocation Failure) [PSYoungGen: 232960K->5516K(465920K)] 391270K->163827K(1864192K), 0.0021813 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
96.165: [Full GC (Ergonomics) [PSYoungGen: 5516K->0K(465920K)] [ParOldGen: 158310K->158313K(1398272K)] 163827K->158313K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0419858 secs] [Times: user=0.16 sys=0.00, real=0.04 secs] 
96.439: [GC (Allocation Failure) [PSYoungGen: 232960K->6633K(465920K)] 391273K->164946K(1864192K), 0.0021030 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
96.441: [Full GC (Ergonomics) [PSYoungGen: 6633K->0K(465920K)] [ParOldGen: 158313K->158314K(1398272K)] 164946K->158314K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0400108 secs] [Times: user=0.15 sys=0.00, real=0.04 secs] 
96.710: [GC (Allocation Failure) [PSYoungGen: 232960K->9803K(465920K)] 391274K->168118K(1864192K), 0.0021182 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
96.712: [Full GC (Ergonomics) [PSYoungGen: 9803K->0K(465920K)] [ParOldGen: 158314K->158255K(1398272K)] 168118K->158255K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0785354 secs] [Times: user=0.41 sys=0.00, real=0.07 secs] 
97.022: [GC (Allocation Failure) [PSYoungGen: 232960K->9557K(465920K)] 391215K->167812K(1864192K), 0.0020421 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
97.024: [Full GC (Ergonomics) [PSYoungGen: 9557K->0K(465920K)] [ParOldGen: 158255K->158255K(1398272K)] 167812K->158255K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0503176 secs] [Times: user=0.15 sys=0.00, real=0.05 secs] 
97.325: [GC (Allocation Failure) [PSYoungGen: 232960K->7588K(465920K)] 391215K->165844K(1864192K), 0.0019582 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
97.327: [Full GC (Ergonomics) [PSYoungGen: 7588K->0K(465920K)] [ParOldGen: 158255K->158253K(1398272K)] 165844K->158253K(1864192K), [Metaspace: 51218K->51218K(1095680K)], 0.0422235 secs] [Times: user=0.14 sys=0.00, real=0.04 secs] 
97.598: [GC (Allocation Failure) [PSYoungGen: 232960K->5577K(238592K)] 391213K->163830K(1636864K), 0.0021031 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
97.600: [Full GC (Ergonomics) [PSYoungGen: 5577K->0K(238592K)] [ParOldGen: 158253K->158253K(1398272K)] 163830K->158253K(1636864K), [Metaspace: 51218K->51218K(1095680K)], 0.0416163 secs] [Times: user=0.12 sys=0.00, real=0.05 secs] 
97.870: [GC (Allocation Failure) [PSYoungGen: 232960K->11783K(439296K)] 391213K->170036K(1837568K), 0.0027407 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
97.873: [Full GC (Ergonomics) [PSYoungGen: 11783K->0K(439296K)] [ParOldGen: 158253K->158257K(1398272K)] 170036K->158257K(1837568K), [Metaspace: 51218K->51218K(1095680K)], 0.0435581 secs] [Times: user=0.14 sys=0.00, real=0.04 secs] 
98.150: [GC (Allocation Failure) [PSYoungGen: 235520K->8564K(244224K)] 393777K->166822K(1642496K), 0.0022931 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
98.153: [Full GC (Ergonomics) [PSYoungGen: 8564K->0K(244224K)] [ParOldGen: 158257K->158236K(1398272K)] 166822K->158236K(1642496K), [Metaspace: 51218K->51218K(1095680K)], 0.0439065 secs] [Times: user=0.17 sys=0.00, real=0.04 secs] 
98.426: [GC (Allocation Failure) [PSYoungGen: 235520K->5530K(414720K)] 393756K->163766K(1812992K), 0.0020979 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
98.428: [Full GC (Ergonomics) [PSYoungGen: 5530K->0K(414720K)] [ParOldGen: 158236K->158236K(1398272K)] 163766K->158236K(1812992K), [Metaspace: 51218K->51218K(1095680K)], 0.0413371 secs] [Times: user=0.15 sys=0.00, real=0.04 secs] 
98.704: [GC (Allocation Failure) [PSYoungGen: 237568K->9557K(247296K)] 395804K->167793K(1645568K), 0.0023972 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
98.707: [Full GC (Ergonomics) [PSYoungGen: 9557K->0K(247296K)] [ParOldGen: 158236K->158235K(1398272K)] 167793K->158235K(1645568K), [Metaspace: 51218K->51218K(1095680K)], 0.0414907 secs] [Times: user=0.14 sys=0.01, real=0.04 secs] 
98.982: [GC (Allocation Failure) [PSYoungGen: 237454K->10740K(393216K)] 395690K->168975K(1791488K), 0.0024055 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
98.984: [Full GC (Ergonomics) [PSYoungGen: 10740K->0K(393216K)] [ParOldGen: 158235K->158189K(1398272K)] 168975K->158189K(1791488K), [Metaspace: 51218K->51218K(1095680K)], 0.0421012 secs] [Times: user=0.16 sys=0.00, real=0.04 secs] 
[2018/03/29-12:41:37.893] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=28973661
[2018/03/29-12:41:37.893] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:37.900] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:37.900] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
99.604: [GC (Allocation Failure) [PSYoungGen: 240128K->13256K(253440K)] 530124K->303252K(1651712K), 0.0047116 secs] [Times: user=0.03 sys=0.00, real=0.00 secs] 
99.609: [Full GC (Ergonomics) [PSYoungGen: 13256K->0K(253440K)] [ParOldGen: 289996K->155867K(1398272K)] 303252K->155867K(1651712K), [Metaspace: 51221K->51221K(1095680K)], 0.0588084 secs] [Times: user=0.27 sys=0.00, real=0.06 secs] 
[2018/03/29-12:41:38.479] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:38.487] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
99.918: [GC (Allocation Failure) [PSYoungGen: 240128K->986K(378368K)] 395995K->156853K(1776640K), 0.0023146 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] 
99.920: [Full GC (Ergonomics) [PSYoungGen: 986K->0K(378368K)] [ParOldGen: 155867K->155874K(1398272K)] 156853K->155874K(1776640K), [Metaspace: 51221K->51221K(1095680K)], 0.0544640 secs] [Times: user=0.22 sys=0.00, real=0.06 secs] 
100.224: [GC (Allocation Failure) [PSYoungGen: 242688K->2763K(245760K)] 398562K->158638K(1644032K), 0.0036914 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
100.470: [GC (Allocation Failure) [PSYoungGen: 245451K->7213K(363008K)] 401326K->163087K(1761280K), 0.0022071 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
100.715: [GC (Allocation Failure) [PSYoungGen: 252461K->11054K(256512K)] 408335K->166929K(1654784K), 0.0022993 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
100.960: [GC (Allocation Failure) [PSYoungGen: 256302K->12018K(348160K)] 412177K->167893K(1746432K), 0.0024362 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
101.207: [GC (Allocation Failure) [PSYoungGen: 260338K->9938K(258560K)] 416213K->165812K(1656832K), 0.0024066 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
101.451: [GC (Allocation Failure) [PSYoungGen: 258258K->13133K(336896K)] 414132K->169008K(1735168K), 0.0027271 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
101.696: [GC (Allocation Failure) [PSYoungGen: 264525K->6595K(258048K)] 420400K->162470K(1656320K), 0.0022360 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
101.940: [GC (Allocation Failure) [PSYoungGen: 257987K->7631K(329728K)] 413862K->163506K(1728000K), 0.0023849 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
102.188: [GC (Allocation Failure) [PSYoungGen: 262095K->10669K(265216K)] 417970K->166544K(1663488K), 0.0023322 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
102.436: [GC (Allocation Failure) [PSYoungGen: 265133K->13160K(322048K)] 421008K->169035K(1720320K), 0.0042542 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
102.688: [GC (Allocation Failure) [PSYoungGen: 271208K->11123K(269312K)] 427083K->166998K(1667584K), 0.0025881 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
102.940: [GC (Allocation Failure) [PSYoungGen: 269171K->11091K(316928K)] 425046K->166966K(1715200K), 0.0021885 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
103.204: [GC (Allocation Failure) [PSYoungGen: 272211K->10847K(272384K)] 428086K->166722K(1670656K), 0.0023793 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
103.466: [GC (Allocation Failure) [PSYoungGen: 271967K->12901K(311808K)] 427842K->168776K(1710080K), 0.0024936 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
103.732: [GC (Allocation Failure) [PSYoungGen: 277093K->10100K(315904K)] 432968K->165975K(1714176K), 0.0022193 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
103.995: [GC (Allocation Failure) [PSYoungGen: 274292K->9859K(309760K)] 430167K->165742K(1708032K), 0.0023887 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
104.263: [GC (Allocation Failure) [PSYoungGen: 277123K->5286K(312832K)] 433006K->161169K(1711104K), 0.0022816 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:41:42.987] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=30632215
[2018/03/29-12:41:42.987] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:42.996] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:42.996] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
Mar 29, 2018 12:40:47 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:47 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1660100 records.
Mar 29, 2018 12:40:47 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:47 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 283 ms. row count = 1660100
Mar 29, 2018 12:40:52 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:52 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 378700 records.
Mar 29, 2018 12:40:52 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:52 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 44 ms. row count = 378700
Mar 29, 2018 12:40:53 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:53 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:53 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1913198 records.
Mar 29, 2018 12:40:53 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:54 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 251 ms. row count = 1660100
Mar 29, 2018 12:40:58 PM INFO: parquet.hadoop.InternalParquetRecordReader: Assembled and processed 1660100 records from 10 columns in 4688 ms: 354.11688 rec/ms, 3541.169 cell/ms
Mar 29, 2018 12:40:58 PM INFO: parquet.hadoop.InternalParquetRecordReader: time spent so far 5% reading (251 ms) and 94% processing (4688 ms)
Mar 29, 2018 12:40:58 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 1660100. reading next block
Mar 29, 2018 12:40:58 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 32 ms. row count = 253098
Mar 29, 2018 12:40:59 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:40:59 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:40:59 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1652781 records.
Mar 29, 2018 12:40:59 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:40:59 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 298 ms. row count = 1652781
Mar 29, 2018 12:41:04 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:04 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 367444 records.
Mar 29, 2018 12:41:04 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:04 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 49 ms. row count = 367444
Mar 29, 2018 12:41:05 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:41:05 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1660100 records.
Mar 29, 2018 12:41:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:05 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 229 ms. row count = 1660100
Mar 29, 2018 12:41:10 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:10 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1660100 records.
Mar 29, 2018 12:41:10 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:11 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 342 ms. row count = 1660100
Mar 29, 2018 12:41:15 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:15 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1660100 records.
Mar 29, 2018 12:41:15 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:16 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 229 ms. row count = 1660100
Mar 29, 2018 12:41:21 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:21 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1632276 records.
Mar 29, 2018 12:41:21 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:21 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 352 ms. row count = 1632276
Mar 29, 2018 12:41:26 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:41:26 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:26 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1660100 records.
Mar 29, 2018 12:41:26 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:26 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 243 ms. row count = 1660100
Mar 29, 2018 12:41:31 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:31 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1652781 records.
Mar 29, 2018 12:41:31 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:32 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 271 ms. row count = 1652781
Mar 29, 2018 12:41:37 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:37 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1658554 records.
Mar 29, 2018 12:41:37 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:38 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 332 ms. row count = 1658554
Mar 29, 2018 12:41:42 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
104.640: [GC (Allocation Failure) [PSYoungGen: 272550K->12810K(316416K)] 428433K->1077120K(1714688K), 0.0414453 secs] [Times: user=0.28 sys=0.00, real=0.04 secs] 
104.681: [Full GC (Ergonomics) [PSYoungGen: 12810K->0K(316416K)] [ParOldGen: 1064310K->137924K(1398272K)] 1077120K->137924K(1714688K), [Metaspace: 51223K->51223K(1095680K)], 0.0717387 secs] [Times: user=0.24 sys=0.01, real=0.08 secs] 
[2018/03/29-12:41:43.487] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:43.495] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
105.036: [GC (Allocation Failure) [PSYoungGen: 272896K->1008K(313856K)] 410820K->138932K(1712128K), 0.0018166 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
105.311: [GC (Allocation Failure) [PSYoungGen: 273904K->7804K(315392K)] 411828K->145728K(1713664K), 0.0023000 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
105.590: [GC (Allocation Failure) [PSYoungGen: 289404K->10691K(318976K)] 427328K->148615K(1717248K), 0.0032883 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
105.865: [GC (Allocation Failure) [PSYoungGen: 292291K->5443K(325632K)] 430215K->143367K(1723904K), 0.0212590 secs] [Times: user=0.08 sys=0.00, real=0.02 secs] 
106.174: [GC (Allocation Failure) [PSYoungGen: 296259K->12708K(324096K)] 434183K->150632K(1722368K), 0.0022427 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
106.459: [GC (Allocation Failure) [PSYoungGen: 303524K->6865K(327168K)] 441448K->144789K(1725440K), 0.0019500 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
106.754: [GC (Allocation Failure) [PSYoungGen: 306897K->11821K(330240K)] 444821K->149746K(1728512K), 0.0022480 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
107.050: [GC (Allocation Failure) [PSYoungGen: 311853K->12753K(333312K)] 449778K->150677K(1731584K), 0.0021760 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
107.353: [GC (Allocation Failure) [PSYoungGen: 319953K->12842K(335360K)] 457877K->150766K(1733632K), 0.0022125 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
107.654: [GC (Allocation Failure) [PSYoungGen: 320042K->9680K(335872K)] 457966K->147604K(1734144K), 0.0020770 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
107.961: [GC (Allocation Failure) [PSYoungGen: 322512K->10096K(338432K)] 460436K->148020K(1736704K), 0.0022127 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
108.268: [GC (Allocation Failure) [PSYoungGen: 322928K->9917K(338944K)] 460852K->147841K(1737216K), 0.0024665 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
108.579: [GC (Allocation Failure) [PSYoungGen: 327869K->6150K(340992K)] 465793K->144074K(1739264K), 0.0022327 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[2018/03/29-12:41:47.388] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=32092923
[2018/03/29-12:41:47.389] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=32092923 totalRecords=32092923
[2018/03/29-12:41:47.390] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000038_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:41:47.412] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:41:47.414] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:47.419] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:47.419] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
109.058: [GC (Allocation Failure) [PSYoungGen: 324102K->13539K(345088K)] 462026K->1202060K(1743360K), 0.0358674 secs] [Times: user=0.25 sys=0.01, real=0.04 secs] 
109.094: [Full GC (Ergonomics) [PSYoungGen: 13539K->0K(345088K)] [ParOldGen: 1188520K->155464K(1398272K)] 1202060K->155464K(1743360K), [Metaspace: 51240K->51240K(1095680K)], 0.0631268 secs] [Times: user=0.23 sys=0.00, real=0.06 secs] 
109.492: [GC (Allocation Failure) [PSYoungGen: 322560K->880K(345088K)] 478024K->156345K(1743360K), 0.0020072 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:41:48.495] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:48.504] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
109.818: [GC (Allocation Failure) [PSYoungGen: 323279K->3810K(353280K)] 478743K->159274K(1751552K), 0.0024697 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
110.148: [GC (Allocation Failure) [PSYoungGen: 336610K->8545K(355328K)] 492074K->164009K(1753600K), 0.0024706 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
110.475: [GC (Allocation Failure) [PSYoungGen: 341345K->7827K(360448K)] 496809K->163291K(1758720K), 0.0031453 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
110.820: [GC (Allocation Failure) [PSYoungGen: 349331K->6574K(361984K)] 504795K->162038K(1760256K), 0.0023229 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
111.153: [GC (Allocation Failure) [PSYoungGen: 348078K->7659K(366592K)] 503542K->163123K(1764864K), 0.0030025 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
111.524: [GC (Allocation Failure) [PSYoungGen: 356843K->6745K(367616K)] 512307K->162209K(1765888K), 0.0021715 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
111.873: [GC (Allocation Failure) [PSYoungGen: 355929K->11961K(373248K)] 511393K->167425K(1771520K), 0.0031103 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
112.268: [GC (Allocation Failure) [PSYoungGen: 367289K->7685K(373760K)] 522753K->163149K(1772032K), 0.0019004 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
112.623: [GC (Allocation Failure) [PSYoungGen: 363013K->8955K(376832K)] 518477K->164420K(1775104K), 0.0025206 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
112.990: [GC (Allocation Failure) [PSYoungGen: 369915K->7632K(377856K)] 525380K->163096K(1776128K), 0.0021972 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
113.339: [GC (Allocation Failure) [PSYoungGen: 368592K->5644K(380928K)] 524056K->161108K(1779200K), 0.0020339 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
113.693: [GC (Allocation Failure) [PSYoungGen: 371724K->6175K(381952K)] 527188K->161640K(1780224K), 0.0023953 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:41:52.466] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=33745704
[2018/03/29-12:41:52.466] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:52.472] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:52.472] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
114.302: [GC (Allocation Failure) [PSYoungGen: 372255K->9062K(386560K)] 527720K->1214069K(1784832K), 0.0479737 secs] [Times: user=0.31 sys=0.00, real=0.05 secs] 
114.350: [Full GC (Ergonomics) [PSYoungGen: 9062K->0K(386560K)] [ParOldGen: 1205006K->155722K(1398272K)] 1214069K->155722K(1784832K), [Metaspace: 51268K->51268K(1095680K)], 0.0802020 secs] [Times: user=0.29 sys=0.00, real=0.08 secs] 
[2018/03/29-12:41:53.505] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:53.512] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
114.815: [GC (Allocation Failure) [PSYoungGen: 371200K->3226K(386560K)] 526922K->158949K(1784832K), 0.0019878 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
115.184: [GC (Allocation Failure) [PSYoungGen: 374426K->10945K(399872K)] 530149K->166668K(1798144K), 0.0033329 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
115.570: [GC (Allocation Failure) [PSYoungGen: 395969K->6596K(400896K)] 551692K->162319K(1799168K), 0.0022016 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
115.978: [GC (Allocation Failure) [PSYoungGen: 391620K->7524K(409600K)] 547343K->163247K(1807872K), 0.0029249 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
116.392: [GC (Allocation Failure) [PSYoungGen: 403812K->7631K(411136K)] 559535K->163354K(1809408K), 0.0028095 secs] [Times: user=0.01 sys=0.01, real=0.01 secs] 
116.794: [GC (Allocation Failure) [PSYoungGen: 403919K->8890K(419328K)] 559642K->164613K(1817600K), 0.0032804 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] 
117.240: [GC (Allocation Failure) [PSYoungGen: 414906K->6794K(419840K)] 570629K->162517K(1818112K), 0.0019726 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
117.649: [GC (Allocation Failure) [PSYoungGen: 412810K->8656K(428032K)] 568533K->164379K(1826304K), 0.0028550 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
118.066: [GC (Allocation Failure) [PSYoungGen: 423376K->5453K(428032K)] 579099K->161176K(1826304K), 0.0024181 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
118.468: [GC (Allocation Failure) [PSYoungGen: 420173K->12751K(435200K)] 575896K->168474K(1833472K), 0.0034921 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
118.941: [GC (Allocation Failure) [PSYoungGen: 434639K->8257K(436224K)] 590362K->163980K(1834496K), 0.0020685 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:41:57.764] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=35405804
[2018/03/29-12:41:57.764] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:41:57.770] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:41:57.770] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
119.495: [GC (Allocation Failure) [PSYoungGen: 430145K->13812K(224256K)] 585868K->1224482K(1622528K), 0.0353806 secs] [Times: user=0.25 sys=0.01, real=0.03 secs] 
119.530: [Full GC (Ergonomics) [PSYoungGen: 13812K->0K(224256K)] [ParOldGen: 1210670K->155525K(1398272K)] 1224482K->155525K(1622528K), [Metaspace: 51271K->51271K(1095680K)], 0.0722623 secs] [Times: user=0.32 sys=0.00, real=0.08 secs] 
[2018/03/29-12:41:58.513] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:41:58.520] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
119.829: [GC (Allocation Failure) [PSYoungGen: 210432K->497K(443392K)] 365957K->156023K(1841664K), 0.0022807 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
120.050: [GC (Allocation Failure) [PSYoungGen: 210929K->5252K(452096K)] 366455K->160778K(1850368K), 0.0022021 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
120.270: [GC (Allocation Failure) [PSYoungGen: 224900K->8951K(452608K)] 380426K->164477K(1850880K), 0.0024334 secs] [Times: user=0.01 sys=0.01, real=0.01 secs] 
120.507: [GC (Allocation Failure) [PSYoungGen: 228599K->10063K(461312K)] 384125K->165589K(1859584K), 0.0028562 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] 
120.742: [GC (Allocation Failure) [PSYoungGen: 238415K->11901K(461312K)] 393941K->167427K(1859584K), 0.0021596 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
120.982: [GC (Allocation Failure) [PSYoungGen: 240253K->4484K(465920K)] 395779K->160010K(1864192K), 0.0024106 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
121.232: [GC (Allocation Failure) [PSYoungGen: 237088K->6501K(465920K)] 392613K->162026K(1864192K), 0.0091615 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
121.475: [GC (Allocation Failure) [PSYoungGen: 239461K->6467K(465920K)] 394986K->162009K(1864192K), 0.0048172 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
121.711: [GC (Allocation Failure) [PSYoungGen: 239427K->11727K(465920K)] 394969K->167277K(1864192K), 0.0024324 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
121.951: [GC (Allocation Failure) [PSYoungGen: 244687K->12952K(465920K)] 400237K->168510K(1864192K), 0.0030018 secs] [Times: user=0.01 sys=0.01, real=0.01 secs] 
122.195: [GC (Allocation Failure) [PSYoungGen: 245912K->12718K(465920K)] 401470K->168276K(1864192K), 0.0099667 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
122.483: [GC (Allocation Failure) [PSYoungGen: 245678K->3342K(455680K)] 401236K->158908K(1853952K), 0.0058177 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
122.743: [GC (Allocation Failure) [PSYoungGen: 236302K->6628K(239616K)] 391868K->162194K(1637888K), 0.0028464 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
122.985: [GC (Allocation Failure) [PSYoungGen: 239588K->6447K(431104K)] 395154K->162013K(1829376K), 0.0032292 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
123.278: [GC (Allocation Failure) [PSYoungGen: 250159K->5457K(249344K)] 405725K->161022K(1647616K), 0.0042680 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
123.535: [GC (Allocation Failure) [PSYoungGen: 249169K->3376K(422400K)] 404734K->158942K(1820672K), 0.0049895 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
123.821: [GC (Allocation Failure) [PSYoungGen: 258864K->3344K(433152K)] 414430K->158910K(1831424K), 0.0037027 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
124.241: [GC (Allocation Failure) [PSYoungGen: 258832K->4432K(408576K)] 414398K->159998K(1806848K), 0.0023545 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
124.510: [GC (Allocation Failure) [PSYoungGen: 269648K->3306K(268800K)] 425214K->158872K(1667072K), 0.0027274 secs] [Times: user=0.01 sys=0.01, real=0.01 secs] 
[2018/03/29-12:42:03.256] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=37064358
[2018/03/29-12:42:03.256] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:03.263] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:03.263] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:42:03.520] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:03.531] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
124.927: [GC (Allocation Failure) [PSYoungGen: 268522K->95874K(404992K)] 424088K->757848K(1803264K), 0.0341407 secs] [Times: user=0.16 sys=0.02, real=0.03 secs] 
125.243: [GC (Allocation Failure) [PSYoungGen: 355458K->15586K(420352K)] 1017432K->677561K(1818624K), 0.0053824 secs] [Times: user=0.03 sys=0.00, real=0.00 secs] 
125.525: [GC (Allocation Failure) [PSYoungGen: 275170K->12281K(412672K)] 937145K->674255K(1810944K), 0.0160118 secs] [Times: user=0.05 sys=0.00, real=0.01 secs] 
125.836: [GC (Allocation Failure) [PSYoungGen: 291321K->18365K(419328K)] 953295K->680340K(1817600K), 0.0064114 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
126.129: [GC (Allocation Failure) [PSYoungGen: 297405K->15617K(410112K)] 959380K->677591K(1808384K), 0.0087178 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
126.445: [GC (Allocation Failure) [PSYoungGen: 314113K->15741K(419328K)] 976087K->677715K(1817600K), 0.0063173 secs] [Times: user=0.03 sys=0.00, real=0.00 secs] 
126.773: [GC (Allocation Failure) [PSYoungGen: 314237K->13710K(416256K)] 976211K->675684K(1814528K), 0.0086693 secs] [Times: user=0.03 sys=0.00, real=0.00 secs] 
127.088: [GC (Allocation Failure) [PSYoungGen: 331662K->24386K(423424K)] 993636K->686361K(1821696K), 0.0060222 secs] [Times: user=0.04 sys=0.00, real=0.01 secs] 
127.417: [GC (Allocation Failure) [PSYoungGen: 342338K->22290K(418304K)] 1004313K->684265K(1816576K), 0.0065767 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
127.773: [GC (Allocation Failure) [PSYoungGen: 359186K->12211K(427008K)] 1021161K->674186K(1825280K), 0.0285348 secs] [Times: user=0.04 sys=0.00, real=0.02 secs] 
128.160: [GC (Allocation Failure) [PSYoungGen: 349107K->11984K(436224K)] 1011082K->673958K(1834496K), 0.0081165 secs] [Times: user=0.03 sys=0.00, real=0.01 secs] 
[2018/03/29-12:42:06.901] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=38192123
[2018/03/29-12:42:06.901] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=38192123 totalRecords=38192123
[2018/03/29-12:42:06.903] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000039_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:42:06.930] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:42:06.932] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:06.938] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:06.938] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
128.699: [GC (Allocation Failure) --[PSYoungGen: 373968K->373968K(436224K)] 1035942K->1694952K(1834496K), 0.1150797 secs] [Times: user=0.35 sys=0.00, real=0.12 secs] 
128.814: [Full GC (Ergonomics) [PSYoungGen: 373968K->0K(436224K)] [ParOldGen: 1320984K->155986K(1398272K)] 1694952K->155986K(1834496K), [Metaspace: 51282K->51282K(1095680K)], 0.0825435 secs] [Times: user=0.27 sys=0.01, real=0.08 secs] 
129.271: [GC (Allocation Failure) [PSYoungGen: 361984K->6960K(442368K)] 517970K->162947K(1840640K), 0.0023657 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
129.638: [GC (Allocation Failure) [PSYoungGen: 368944K->3675K(462848K)] 524931K->159661K(1861120K), 0.0020952 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:08.532] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:08.539] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
130.035: [GC (Allocation Failure) [PSYoungGen: 400475K->4698K(470528K)] 556461K->160685K(1868800K), 0.0023125 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
130.434: [GC (Allocation Failure) [PSYoungGen: 401498K->7902K(483840K)] 557485K->163889K(1882112K), 0.0020282 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
130.857: [GC (Allocation Failure) [PSYoungGen: 433886K->8811K(492032K)] 589873K->164797K(1890304K), 0.0020381 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
131.283: [GC (Allocation Failure) [PSYoungGen: 434795K->8678K(500736K)] 590781K->164665K(1899008K), 0.0030930 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
131.728: [GC (Allocation Failure) [PSYoungGen: 458214K->9769K(507904K)] 614201K->165756K(1906176K), 0.0021999 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
132.173: [GC (Allocation Failure) [PSYoungGen: 459305K->7017K(514560K)] 615292K->163004K(1912832K), 0.0028569 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
132.649: [GC (Allocation Failure) [PSYoungGen: 475497K->6628K(520192K)] 631484K->162615K(1918464K), 0.0023504 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
133.118: [GC (Allocation Failure) [PSYoungGen: 475108K->5752K(526848K)] 631095K->161739K(1925120K), 0.0028073 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
[2018/03/29-12:42:12.073] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=39850677
[2018/03/29-12:42:12.073] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:12.079] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:12.079] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
133.734: [GC (Allocation Failure) [PSYoungGen: 490104K->12503K(530944K)] 646091K->1218263K(1929216K), 0.0531617 secs] [Times: user=0.32 sys=0.01, real=0.05 secs] 
133.787: [Full GC (Ergonomics) [PSYoungGen: 12503K->0K(530944K)] [ParOldGen: 1205760K->155707K(1398272K)] 1218263K->155707K(1929216K), [Metaspace: 51284K->51284K(1095680K)], 0.0651322 secs] [Times: user=0.22 sys=0.00, real=0.07 secs] 
134.363: [GC (Allocation Failure) [PSYoungGen: 484352K->5432K(559104K)] 640059K->161140K(1957376K), 0.0028404 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
[2018/03/29-12:42:13.539] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:13.547] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
134.892: [GC (Allocation Failure) [PSYoungGen: 525624K->8825K(561664K)] 681332K->164541K(1959936K), 0.0024028 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
135.414: [GC (Allocation Failure) [PSYoungGen: 529017K->10911K(578048K)] 684733K->166627K(1976320K), 0.0030078 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
135.945: [GC (Allocation Failure) [PSYoungGen: 560287K->9794K(585216K)] 716003K->165510K(1983488K), 0.0032341 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
136.491: [GC (Allocation Failure) [PSYoungGen: 559170K->5607K(602112K)] 714886K->161323K(2000384K), 0.0029891 secs] [Times: user=0.00 sys=0.01, real=0.01 secs] 
137.050: [GC (Allocation Failure) [PSYoungGen: 579559K->9985K(606208K)] 735275K->165701K(2004480K), 0.0029972 secs] [Times: user=0.01 sys=0.01, real=0.01 secs] 
137.607: [GC (Allocation Failure) [PSYoungGen: 583937K->8592K(620032K)] 739653K->164308K(2018304K), 0.0031581 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
138.186: [GC (Allocation Failure) [PSYoungGen: 603536K->10866K(623616K)] 759252K->166582K(2021888K), 0.0024775 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:17.070] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=41510777
[2018/03/29-12:42:17.070] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:17.076] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:17.076] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
138.938: [GC (Allocation Failure) [PSYoungGen: 605810K->11559K(642560K)] 761526K->1216247K(2040832K), 0.0364857 secs] [Times: user=0.26 sys=0.02, real=0.04 secs] 
138.974: [Full GC (Ergonomics) [PSYoungGen: 11559K->0K(642560K)] [ParOldGen: 1204687K->155514K(1398272K)] 1216247K->155514K(2040832K), [Metaspace: 51295K->51295K(1095680K)], 0.0725479 secs] [Times: user=0.27 sys=0.00, real=0.07 secs] 
139.664: [GC (Allocation Failure) [PSYoungGen: 615424K->7619K(641536K)] 770938K->163133K(2039808K), 0.0025837 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
[2018/03/29-12:42:18.547] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:18.554] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
140.267: [GC (Allocation Failure) [PSYoungGen: 623043K->9910K(671232K)] 778557K->165424K(2069504K), 0.0034818 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
140.899: [GC (Allocation Failure) [PSYoungGen: 656566K->8657K(670208K)] 812080K->164171K(2068480K), 0.0024897 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
141.530: [GC (Allocation Failure) [PSYoungGen: 655313K->7595K(674304K)] 810827K->163110K(2072576K), 0.0026664 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
142.178: [GC (Allocation Failure) [PSYoungGen: 659371K->7566K(673280K)] 814886K->163080K(2071552K), 0.0025642 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
142.819: [GC (Allocation Failure) [PSYoungGen: 659342K->7628K(675840K)] 814856K->163142K(2074112K), 0.0024089 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:22.057] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=43170877
[2018/03/29-12:42:22.057] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:22.063] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:22.063] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
143.359: [GC (Allocation Failure) [PSYoungGen: 560133K->9875K(675328K)] 715647K->165397K(2073600K), 0.0027481 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
144.168: [GC (Allocation Failure) [PSYoungGen: 665235K->18934K(251904K)] 820757K->1056843K(1650176K), 0.0336895 secs] [Times: user=0.24 sys=0.01, real=0.03 secs] 
144.202: [Full GC (Ergonomics) [PSYoungGen: 18934K->0K(251904K)] [ParOldGen: 1037908K->135735K(1398272K)] 1056843K->135735K(1650176K), [Metaspace: 51302K->51302K(1095680K)], 0.0580724 secs] [Times: user=0.25 sys=0.00, real=0.06 secs] 
144.490: [GC (Allocation Failure) [PSYoungGen: 232960K->6478K(465920K)] 368695K->142214K(1864192K), 0.0020925 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
144.726: [GC (Allocation Failure) [PSYoungGen: 239438K->5473K(465920K)] 375174K->141209K(1864192K), 0.0018949 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:23.554] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:23.563] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
144.970: [GC (Allocation Failure) [PSYoungGen: 238433K->5473K(465920K)] 374169K->141209K(1864192K), 0.0020275 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
145.210: [GC (Allocation Failure) [PSYoungGen: 238433K->10659K(465920K)] 374169K->146395K(1864192K), 0.0020967 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
145.446: [GC (Allocation Failure) [PSYoungGen: 243619K->8643K(465920K)] 379355K->144379K(1864192K), 0.0020063 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
145.680: [GC (Allocation Failure) [PSYoungGen: 241603K->9635K(465920K)] 377339K->145371K(1864192K), 0.0019186 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
145.914: [GC (Allocation Failure) [PSYoungGen: 242595K->7746K(465920K)] 378331K->143482K(1864192K), 0.0020664 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
146.144: [GC (Allocation Failure) [PSYoungGen: 240706K->4546K(465920K)] 376442K->140297K(1864192K), 0.0022024 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
146.370: [GC (Allocation Failure) [PSYoungGen: 237506K->9765K(465920K)] 373257K->145557K(1864192K), 0.0022487 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
146.597: [GC (Allocation Failure) [PSYoungGen: 242725K->8715K(442368K)] 378517K->144507K(1840640K), 0.0023458 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
146.830: [GC (Allocation Failure) [PSYoungGen: 241675K->10705K(243712K)] 377467K->146497K(1641984K), 0.0024982 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
147.062: [GC (Allocation Failure) [PSYoungGen: 243665K->10705K(427520K)] 379457K->146497K(1825792K), 0.0022220 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
147.300: [GC (Allocation Failure) [PSYoungGen: 255953K->6617K(440320K)] 391745K->142409K(1838592K), 0.0020768 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
147.537: [GC (Allocation Failure) [PSYoungGen: 251865K->10770K(417792K)] 387657K->146562K(1816064K), 0.0022434 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:26.352] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=44579274
[2018/03/29-12:42:26.353] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=44579274 totalRecords=44579274
[2018/03/29-12:42:26.354] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000040_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:42:26.373] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:42:26.375] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:26.379] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:26.379] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
147.919: [GC (Allocation Failure) [PSYoungGen: 268306K->160738K(429568K)] 404098K->745728K(1827840K), 0.0210637 secs] [Times: user=0.14 sys=0.00, real=0.02 secs] 
148.188: [GC (Allocation Failure) [PSYoungGen: 418274K->157378K(440320K)] 1003264K->1116699K(1838592K), 0.0248526 secs] [Times: user=0.15 sys=0.01, real=0.03 secs] 
148.213: [Full GC (Ergonomics) [PSYoungGen: 157378K->0K(440320K)] [ParOldGen: 959321K->95668K(1398272K)] 1116699K->95668K(1838592K), [Metaspace: 51304K->51304K(1095680K)], 0.0446145 secs] [Times: user=0.16 sys=0.00, real=0.04 secs] 
148.480: [GC (Allocation Failure) [PSYoungGen: 233984K->6448K(466432K)] 329652K->102116K(1864704K), 0.0022021 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
148.706: [GC (Allocation Failure) [PSYoungGen: 240432K->8560K(436224K)] 336100K->104228K(1834496K), 0.0022737 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
148.952: [GC (Allocation Failure) [PSYoungGen: 252272K->12807K(456192K)] 347940K->108475K(1854464K), 0.0023602 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
149.195: [GC (Allocation Failure) [PSYoungGen: 256519K->9685K(444416K)] 352187K->105353K(1842688K), 0.0021388 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
149.470: [GC (Allocation Failure) [PSYoungGen: 275413K->11733K(456704K)] 371081K->107401K(1854976K), 0.0021553 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
149.742: [GC (Allocation Failure) [PSYoungGen: 277461K->5738K(446464K)] 373129K->101406K(1844736K), 0.0025825 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
[2018/03/29-12:42:28.564] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:28.571] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
150.030: [GC (Allocation Failure) [PSYoungGen: 291946K->11755K(457216K)] 387614K->107424K(1855488K), 0.0022357 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
150.319: [GC (Allocation Failure) [PSYoungGen: 297963K->9804K(446464K)] 393632K->105472K(1844736K), 0.0022617 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:29.058] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=45435872
[2018/03/29-12:42:29.058] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=45435872 totalRecords=45435872
[2018/03/29-12:42:29.060] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000041_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:42:29.078] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:42:29.079] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:29.084] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:29.084] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
150.752: [GC (Allocation Failure) [PSYoungGen: 314956K->88781K(456704K)] 410624K->714615K(1854976K), 0.0269555 secs] [Times: user=0.18 sys=0.00, real=0.02 secs] 
151.077: [GC (Allocation Failure) [PSYoungGen: 393933K->8997K(476160K)] 1019767K->634830K(1874432K), 0.0027784 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
151.413: [GC (Allocation Failure) [PSYoungGen: 342821K->16251K(486912K)] 968654K->642084K(1885184K), 0.0033376 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
151.768: [GC (Allocation Failure) [PSYoungGen: 350075K->12824K(484352K)] 975908K->638657K(1882624K), 0.0030166 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
152.133: [GC (Allocation Failure) [PSYoungGen: 373272K->14673K(495616K)] 999105K->640506K(1893888K), 0.0031773 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
152.505: [GC (Allocation Failure) [PSYoungGen: 375121K->9604K(499712K)] 1000954K->635437K(1897984K), 0.0042477 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
152.948: [GC (Allocation Failure) [PSYoungGen: 396164K->7985K(506880K)] 1021997K->633818K(1905152K), 0.0031330 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:31.830] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=46302692
[2018/03/29-12:42:31.830] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=46302692 totalRecords=46302692
[2018/03/29-12:42:31.831] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000042_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:42:31.851] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:42:31.852] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:31.856] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:31.856] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
153.452: [GC (Allocation Failure) [PSYoungGen: 394545K->84257K(513024K)] 1020378K->1241034K(1911296K), 0.0260302 secs] [Times: user=0.18 sys=0.01, real=0.02 secs] 
153.478: [Full GC (Ergonomics) [PSYoungGen: 84257K->0K(513024K)] [ParOldGen: 1156776K->96700K(1398272K)] 1241034K->96700K(1911296K), [Metaspace: 51320K->51320K(1095680K)], 0.0478655 secs] [Times: user=0.16 sys=0.00, real=0.05 secs] 
153.938: [GC (Allocation Failure) [PSYoungGen: 399360K->11659K(526336K)] 496060K->108360K(1924608K), 0.0031852 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
154.337: [GC (Allocation Failure) [PSYoungGen: 411019K->10791K(538112K)] 507720K->107491K(1936384K), 0.0021909 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
154.774: [GC (Allocation Failure) [PSYoungGen: 444455K->6612K(547840K)] 541155K->103313K(1946112K), 0.0026359 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:33.571] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:33.579] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
155.224: [GC (Allocation Failure) [PSYoungGen: 440276K->6645K(576512K)] 536977K->103345K(1974784K), 0.0119768 secs] [Times: user=0.04 sys=0.00, real=0.01 secs] 
155.718: [GC (Allocation Failure) [PSYoungGen: 479733K->9837K(576512K)] 576433K->106538K(1974784K), 0.0020800 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:34.592] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=47171462
[2018/03/29-12:42:34.592] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=47171462 totalRecords=47171462
[2018/03/29-12:42:34.594] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000043_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:42:34.614] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:42:34.617] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:34.622] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:34.622] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
156.289: [GC (Allocation Failure) [PSYoungGen: 482925K->80233K(573440K)] 579626K->692491K(1971712K), 0.0335247 secs] [Times: user=0.20 sys=0.01, real=0.04 secs] 
156.779: [GC (Allocation Failure) [PSYoungGen: 555881K->8362K(587264K)] 1168139K->620620K(1985536K), 0.0029613 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
157.242: [GC (Allocation Failure) [PSYoungGen: 484010K->12039K(570880K)] 1096268K->624297K(1969152K), 0.0028489 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
157.712: [GC (Allocation Failure) [PSYoungGen: 492807K->8841K(581632K)] 1105065K->621099K(1979904K), 0.0038722 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
158.184: [GC (Allocation Failure) [PSYoungGen: 489609K->8376K(582656K)] 1101867K->620634K(1980928K), 0.0031638 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:37.120] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=48014590
[2018/03/29-12:42:37.120] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=48014590 totalRecords=48014590
[2018/03/29-12:42:37.122] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000044_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:42:37.141] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:42:37.142] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:37.149] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:37.149] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
Mar 29, 2018 12:41:42 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1460708 records.
Mar 29, 2018 12:41:42 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:43 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 212 ms. row count = 1460708
Mar 29, 2018 12:41:47 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:41:47 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:47 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1652781 records.
Mar 29, 2018 12:41:47 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:47 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 265 ms. row count = 1652781
Mar 29, 2018 12:41:52 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:52 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1660100 records.
Mar 29, 2018 12:41:52 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:52 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 360 ms. row count = 1660100
Mar 29, 2018 12:41:57 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:41:57 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1658554 records.
Mar 29, 2018 12:41:57 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:41:58 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 258 ms. row count = 1658554
Mar 29, 2018 12:42:03 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:03 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1127765 records.
Mar 29, 2018 12:42:03 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:03 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 179 ms. row count = 1127765
Mar 29, 2018 12:42:06 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:42:06 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1658554 records.
Mar 29, 2018 12:42:06 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:07 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 250 ms. row count = 1658554
Mar 29, 2018 12:42:12 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:12 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1660100 records.
Mar 29, 2018 12:42:12 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:12 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 249 ms. row count = 1660100
Mar 29, 2018 12:42:17 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:17 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1660100 records.
Mar 29, 2018 12:42:17 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:17 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 272 ms. row count = 1660100
Mar 29, 2018 12:42:22 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:22 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1408397 records.
Mar 29, 2018 12:42:22 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:22 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 263 ms. row count = 1408397
Mar 29, 2018 12:42:26 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:42:26 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:26 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 856598 records.
Mar 29, 2018 12:42:26 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:26 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 184 ms. row count = 856598
Mar 29, 2018 12:42:29 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:42:29 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 866820 records.
Mar 29, 2018 12:42:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 188 ms. row count = 866820
Mar 29, 2018 12:42:31 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:42:31 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:31 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 868770 records.
Mar 29, 2018 12:42:31 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:32 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 165 ms. row count = 868770
Mar 29, 2018 12:42:34 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:42:34 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:34 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 843128 records.
Mar 29, 2018 12:42:34 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:34 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 155 ms. row count = 843128
Mar 29, 2018 12:42:37 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:42:37 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
158.819: [GC (Allocation Failure) --[PSYoungGen: 510648K->510648K(582656K)] 1122906K->1889602K(1980928K), 0.1402958 secs] [Times: user=0.37 sys=0.00, real=0.14 secs] 
158.959: [Full GC (Ergonomics) [PSYoungGen: 510648K->0K(582656K)] [ParOldGen: 1378953K->148669K(1398272K)] 1889602K->148669K(1980928K), [Metaspace: 51335K->51335K(1095680K)], 0.0592425 secs] [Times: user=0.22 sys=0.00, real=0.06 secs] 
159.510: [GC (Allocation Failure) [PSYoungGen: 502272K->6685K(592896K)] 650941K->155355K(1991168K), 0.0019965 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:42:38.579] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:38.586] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
160.028: [GC (Allocation Failure) [PSYoungGen: 508957K->6680K(595456K)] 657627K->155349K(1993728K), 0.0023058 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
160.580: [GC (Allocation Failure) [PSYoungGen: 528920K->10003K(604160K)] 677589K->158672K(2002432K), 0.0027928 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
161.100: [GC (Allocation Failure) [PSYoungGen: 532243K->10819K(604160K)] 680912K->159488K(2002432K), 0.0024585 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
161.634: [GC (Allocation Failure) [PSYoungGen: 550979K->5449K(612352K)] 699648K->154118K(2010624K), 0.0029112 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
162.178: [GC (Allocation Failure) [PSYoungGen: 545609K->6504K(615936K)] 694278K->155174K(2014208K), 0.0022098 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
162.734: [GC (Allocation Failure) [PSYoungGen: 564584K->10893K(623104K)] 713254K->159563K(2021376K), 0.0023908 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:41.731] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=49474690
[2018/03/29-12:42:41.731] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:41.739] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:41.739] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
163.425: [GC (Allocation Failure) [PSYoungGen: 568973K->8385K(624128K)] 717643K->1193824K(2022400K), 0.0566031 secs] [Times: user=0.37 sys=0.00, real=0.05 secs] 
163.482: [Full GC (Ergonomics) [PSYoungGen: 8385K->0K(624128K)] [ParOldGen: 1185439K->153644K(1398272K)] 1193824K->153644K(2022400K), [Metaspace: 51342K->51342K(1095680K)], 0.0662427 secs] [Times: user=0.25 sys=0.00, real=0.07 secs] 
164.136: [GC (Allocation Failure) [PSYoungGen: 573440K->5188K(630272K)] 727084K->158832K(2028544K), 0.0020389 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
164.706: [GC (Allocation Failure) [PSYoungGen: 578628K->8604K(632320K)] 732272K->162249K(2030592K), 0.0023812 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:43.586] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:43.593] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
165.287: [GC (Allocation Failure) [PSYoungGen: 596380K->8840K(638464K)] 750025K->162485K(2036736K), 0.0020116 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
165.861: [GC (Allocation Failure) [PSYoungGen: 596616K->6530K(640000K)] 750261K->160175K(2038272K), 0.0027654 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
166.450: [GC (Allocation Failure) [PSYoungGen: 607106K->5478K(645632K)] 760751K->159123K(2043904K), 0.0022633 secs] [Times: user=0.00 sys=0.01, real=0.01 secs] 
167.041: [GC (Allocation Failure) [PSYoungGen: 606054K->8728K(646144K)] 759699K->162373K(2044416K), 0.0019228 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
167.641: [GC (Allocation Failure) [PSYoungGen: 620056K->6598K(651264K)] 773701K->160242K(2049536K), 0.0019555 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:42:46.803] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=51164790
[2018/03/29-12:42:46.803] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:46.810] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:46.810] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
168.383: [GC (Allocation Failure) [PSYoungGen: 617926K->7772K(651776K)] 771570K->1197549K(2050048K), 0.0545190 secs] [Times: user=0.36 sys=0.00, real=0.05 secs] 
168.437: [Full GC (Ergonomics) [PSYoungGen: 7772K->0K(651776K)] [ParOldGen: 1189776K->153535K(1398272K)] 1197549K->153535K(2050048K), [Metaspace: 51348K->51348K(1095680K)], 0.0659454 secs] [Times: user=0.27 sys=0.00, real=0.07 secs] 
169.137: [GC (Allocation Failure) [PSYoungGen: 621056K->5258K(656384K)] 774591K->158794K(2054656K), 0.0019781 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
169.749: [GC (Allocation Failure) [PSYoungGen: 626314K->7688K(657920K)] 779850K->161224K(2056192K), 0.0029568 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
[2018/03/29-12:42:48.593] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:48.602] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
170.386: [GC (Allocation Failure) [PSYoungGen: 637448K->10869K(661504K)] 790984K->164404K(2059776K), 0.0027594 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
171.015: [GC (Allocation Failure) [PSYoungGen: 640629K->7728K(661504K)] 794164K->161263K(2059776K), 0.0034195 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
171.663: [GC (Allocation Failure) [PSYoungGen: 644656K->8710K(665088K)] 798191K->162246K(2063360K), 0.0026161 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
172.307: [GC (Allocation Failure) [PSYoungGen: 645638K->12903K(668160K)] 799174K->166438K(2066432K), 0.0030786 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
172.964: [GC (Allocation Failure) [PSYoungGen: 656999K->5524K(670208K)] 810534K->159060K(2068480K), 0.0024447 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:51.970] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=52854890
[2018/03/29-12:42:51.970] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:51.977] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:51.977] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
173.818: [GC (Allocation Failure) [PSYoungGen: 649620K->8162K(669696K)] 803156K->1200789K(2067968K), 0.0539646 secs] [Times: user=0.33 sys=0.00, real=0.05 secs] 
173.872: [Full GC (Ergonomics) [PSYoungGen: 8162K->0K(669696K)] [ParOldGen: 1192626K->153896K(1398272K)] 1200789K->153896K(2067968K), [Metaspace: 51354K->51354K(1095680K)], 0.0633641 secs] [Times: user=0.26 sys=0.00, real=0.07 secs] 
174.593: [GC (Allocation Failure) [PSYoungGen: 647680K->3668K(671744K)] 801576K->157564K(2070016K), 0.0022191 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:53.603] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:53.610] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
175.219: [GC (Allocation Failure) [PSYoungGen: 651348K->10950K(673280K)] 805244K->164847K(2071552K), 0.0024675 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
175.845: [GC (Allocation Failure) [PSYoungGen: 662214K->8649K(674304K)] 816111K->162545K(2072576K), 0.0023746 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
176.469: [GC (Allocation Failure) [PSYoungGen: 659913K->10692K(675328K)] 813809K->164589K(2073600K), 0.0019615 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
177.096: [GC (Allocation Failure) [PSYoungGen: 665028K->7588K(675328K)] 818925K->161484K(2073600K), 0.0023945 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
177.727: [GC (Allocation Failure) [PSYoungGen: 661924K->12820K(676352K)] 815820K->166717K(2074624K), 0.0030240 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
[2018/03/29-12:42:57.031] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=54549133
[2018/03/29-12:42:57.031] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:42:57.038] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:42:57.039] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
178.335: [GC (Allocation Failure) [PSYoungGen: 642963K->2145K(676864K)] 796859K->156041K(2075136K), 0.0019033 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
179.141: [GC (Allocation Failure) [PSYoungGen: 658529K->14116K(676352K)] 812425K->1206931K(2074624K), 0.0363673 secs] [Times: user=0.27 sys=0.00, real=0.04 secs] 
179.177: [Full GC (Ergonomics) [PSYoungGen: 14116K->0K(676352K)] [ParOldGen: 1192814K->153937K(1398272K)] 1206931K->153937K(2074624K), [Metaspace: 51354K->51354K(1095680K)], 0.0638053 secs] [Times: user=0.22 sys=0.00, real=0.06 secs] 
179.889: [GC (Allocation Failure) [PSYoungGen: 655872K->6712K(677376K)] 809809K->160649K(2075648K), 0.0019354 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:42:58.610] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:42:58.619] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
180.537: [GC (Allocation Failure) [PSYoungGen: 662584K->7964K(675328K)] 816521K->161901K(2073600K), 0.0020090 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
181.174: [GC (Allocation Failure) [PSYoungGen: 664860K->6900K(676352K)] 818797K->160838K(2074624K), 0.0022230 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
181.819: [GC (Allocation Failure) [PSYoungGen: 663796K->7937K(676864K)] 817734K->161875K(2075136K), 0.0022079 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
182.475: [GC (Allocation Failure) [PSYoungGen: 668417K->6467K(678400K)] 822355K->160405K(2076672K), 0.0049607 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
183.153: [GC (Allocation Failure) [PSYoungGen: 666947K->7831K(678400K)] 820885K->161768K(2076672K), 0.0020284 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] 
[2018/03/29-12:43:02.130] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=56243376
[2018/03/29-12:43:02.131] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:02.138] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:02.138] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
183.992: [GC (Allocation Failure) [PSYoungGen: 671383K->11114K(679936K)] 825320K->1200712K(2078208K), 0.0403390 secs] [Times: user=0.28 sys=0.00, real=0.05 secs] 
184.032: [Full GC (Ergonomics) [PSYoungGen: 11114K->0K(679936K)] [ParOldGen: 1189598K->153506K(1398272K)] 1200712K->153506K(2078208K), [Metaspace: 51355K->51355K(1095680K)], 0.0618130 secs] [Times: user=0.21 sys=0.00, real=0.06 secs] 
184.788: [GC (Allocation Failure) [PSYoungGen: 663552K->5654K(681984K)] 817058K->159161K(2080256K), 0.0029645 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:03.619] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:03.629] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
185.467: [GC (Allocation Failure) [PSYoungGen: 671254K->7728K(681984K)] 824761K->161234K(2080256K), 0.0023582 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
186.149: [GC (Allocation Failure) [PSYoungGen: 673328K->6465K(681984K)] 826834K->159972K(2080256K), 0.0022641 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
187.008: [GC (Allocation Failure) [PSYoungGen: 673089K->6579K(681984K)] 826596K->160086K(2080256K), 0.0036807 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
187.915: [GC (Allocation Failure) [PSYoungGen: 673203K->8613K(683008K)] 826710K->162120K(2081280K), 0.0023793 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
188.724: [GC (Allocation Failure) [PSYoungGen: 677285K->7487K(683008K)] 830792K->160993K(2081280K), 0.0026844 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:08.086] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=57933476
[2018/03/29-12:43:08.087] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:08.094] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:08.094] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
189.692: [GC (Allocation Failure) [PSYoungGen: 676159K->8549K(684032K)] 829665K->1198043K(2082304K), 0.0540907 secs] [Times: user=0.30 sys=0.00, real=0.05 secs] 
189.747: [Full GC (Ergonomics) [PSYoungGen: 8549K->0K(684032K)] [ParOldGen: 1189493K->153476K(1398272K)] 1198043K->153476K(2082304K), [Metaspace: 51355K->51355K(1095680K)], 0.0697613 secs] [Times: user=0.25 sys=0.00, real=0.07 secs] 
[2018/03/29-12:43:08.629] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:08.637] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
190.571: [GC (Allocation Failure) [PSYoungGen: 670208K->2059K(684032K)] 823684K->155536K(2082304K), 0.0021619 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
191.238: [GC (Allocation Failure) [PSYoungGen: 672267K->12945K(682496K)] 825744K->166422K(2080768K), 0.0034808 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
191.912: [GC (Allocation Failure) [PSYoungGen: 681105K->13765K(681984K)] 834582K->167242K(2080256K), 0.0028538 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
192.553: [GC (Allocation Failure) [PSYoungGen: 681925K->11688K(680960K)] 835402K->165165K(2079232K), 0.0032013 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
193.229: [GC (Allocation Failure) [PSYoungGen: 675752K->8645K(672768K)] 829229K->162121K(2071040K), 0.0027302 secs] [Times: user=0.01 sys=0.01, real=0.01 secs] 
193.953: [GC (Allocation Failure) [PSYoungGen: 672709K->11832K(680448K)] 826185K->165309K(2078720K), 0.0028278 secs] [Times: user=0.02 sys=0.00, real=0.00 secs] 
194.648: [GC (Allocation Failure) [PSYoungGen: 675896K->3771K(680960K)] 829373K->157247K(2079232K), 0.0026649 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:13.365] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=59623576
[2018/03/29-12:43:13.365] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:13.372] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:13.372] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:43:13.638] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:14.284] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
195.586: [GC (Allocation Failure) [PSYoungGen: 667835K->9405K(680960K)] 821311K->1202147K(2079232K), 0.0527494 secs] [Times: user=0.35 sys=0.01, real=0.05 secs] 
195.639: [Full GC (Ergonomics) [PSYoungGen: 9405K->0K(680960K)] [ParOldGen: 1192741K->153984K(1398272K)] 1202147K->153984K(2079232K), [Metaspace: 51360K->51360K(1095680K)], 0.0672145 secs] [Times: user=0.23 sys=0.00, real=0.07 secs] 
196.390: [GC (Allocation Failure) [PSYoungGen: 664947K->5478K(681472K)] 818931K->159463K(2079744K), 0.0023957 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
197.083: [GC (Allocation Failure) [PSYoungGen: 670566K->13143K(680448K)] 824551K->167127K(2078720K), 0.0020983 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
197.759: [GC (Allocation Failure) [PSYoungGen: 677207K->8869K(681472K)] 831191K->162854K(2079744K), 0.0023102 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
198.432: [GC (Allocation Failure) [PSYoungGen: 672933K->12123K(680960K)] 826918K->166108K(2079232K), 0.0020735 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
199.105: [GC (Allocation Failure) [PSYoungGen: 676699K->5510K(681472K)] 830684K->159494K(2079744K), 0.0024807 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
199.772: [GC (Allocation Failure) [PSYoungGen: 670086K->7708K(680960K)] 824070K->161693K(2079232K), 0.0022239 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:18.713] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=61317819
[2018/03/29-12:43:18.713] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:18.720] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:18.720] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
200.548: [GC (Allocation Failure) [PSYoungGen: 672796K->11902K(681472K)] 826781K->1202921K(2079744K), 0.0389871 secs] [Times: user=0.27 sys=0.00, real=0.04 secs] 
200.587: [Full GC (Ergonomics) [PSYoungGen: 11902K->0K(681472K)] [ParOldGen: 1191018K->153695K(1398272K)] 1202921K->153695K(2079744K), [Metaspace: 51361K->51361K(1095680K)], 0.0683556 secs] [Times: user=0.24 sys=0.00, real=0.07 secs] 
[2018/03/29-12:43:19.362] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:19.373] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
201.339: [GC (Allocation Failure) [PSYoungGen: 665088K->6982K(681984K)] 818783K->160677K(2080256K), 0.0019909 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
202.025: [GC (Allocation Failure) [PSYoungGen: 672582K->7556K(681984K)] 826277K->161252K(2080256K), 0.0023392 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
202.736: [GC (Allocation Failure) [PSYoungGen: 673156K->7704K(681984K)] 826852K->161399K(2080256K), 0.0021125 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
203.369: [GC (Allocation Failure) [PSYoungGen: 674328K->6584K(681984K)] 828023K->160280K(2080256K), 0.0023242 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
204.113: [GC (Allocation Failure) [PSYoungGen: 673208K->9771K(683008K)] 826904K->163466K(2081280K), 0.0020129 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
204.747: [GC (Allocation Failure) [PSYoungGen: 677931K->9810K(683008K)] 831626K->163505K(2081280K), 0.0021626 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:23.933] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=63007919
[2018/03/29-12:43:23.933] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:23.939] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:23.939] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
205.573: [GC (Allocation Failure) [PSYoungGen: 677970K->11109K(684032K)] 831665K->1204587K(2082304K), 0.0518069 secs] [Times: user=0.30 sys=0.00, real=0.05 secs] 
205.625: [Full GC (Ergonomics) [PSYoungGen: 11109K->0K(684032K)] [ParOldGen: 1193477K->154051K(1398272K)] 1204587K->154051K(2082304K), [Metaspace: 51361K->51361K(1095680K)], 0.0736035 secs] [Times: user=0.25 sys=0.00, real=0.07 secs] 
[2018/03/29-12:43:24.405] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:24.412] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
206.395: [GC (Allocation Failure) [PSYoungGen: 669184K->7319K(684032K)] 823235K->161370K(2082304K), 0.0021900 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
207.096: [GC (Allocation Failure) [PSYoungGen: 676503K->7673K(683008K)] 830554K->161724K(2081280K), 0.0020855 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
207.808: [GC (Allocation Failure) [PSYoungGen: 676857K->10951K(683520K)] 830908K->165002K(2081792K), 0.0022375 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
208.481: [GC (Allocation Failure) [PSYoungGen: 680135K->6526K(684032K)] 834186K->160577K(2082304K), 0.0020266 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
209.144: [GC (Allocation Failure) [PSYoungGen: 676222K->7628K(684032K)] 830273K->161680K(2082304K), 0.0021291 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
209.790: [GC (Allocation Failure) [PSYoungGen: 677324K->8695K(683520K)] 831376K->162746K(2081792K), 0.0020299 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
210.496: [GC (Allocation Failure) [PSYoungGen: 678903K->4498K(684032K)] 832954K->158549K(2082304K), 0.0023902 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:29.233] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=64728251
[2018/03/29-12:43:29.234] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=64728251 totalRecords=64728251
[2018/03/29-12:43:29.238] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000045_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:43:29.257] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:43:29.260] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:29.265] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:29.265] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:43:29.412] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:29.419] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
211.426: [GC (Allocation Failure) [PSYoungGen: 674706K->7493K(684032K)] 828757K->1188993K(2082304K), 0.0485885 secs] [Times: user=0.31 sys=0.00, real=0.05 secs] 
211.474: [Full GC (Ergonomics) [PSYoungGen: 7493K->0K(684032K)] [ParOldGen: 1181499K->149353K(1398272K)] 1188993K->149353K(2082304K), [Metaspace: 51373K->51373K(1095680K)], 0.0502239 secs] [Times: user=0.19 sys=0.00, real=0.05 secs] 
212.177: [GC (Allocation Failure) [PSYoungGen: 671232K->9762K(684544K)] 820585K->159116K(2082816K), 0.0022642 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
212.815: [GC (Allocation Failure) [PSYoungGen: 680994K->6575K(685568K)] 830348K->155929K(2083840K), 0.0049386 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
213.500: [GC (Allocation Failure) [PSYoungGen: 678831K->7654K(679936K)] 828185K->157007K(2078208K), 0.0022611 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
214.168: [GC (Allocation Failure) [PSYoungGen: 679910K->12147K(684032K)] 829263K->161501K(2082304K), 0.0023569 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
214.854: [GC (Allocation Failure) [PSYoungGen: 683379K->5782K(685056K)] 832733K->155136K(2083328K), 0.0021051 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:33.860] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=66195761
[2018/03/29-12:43:33.861] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:33.867] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:33.867] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
215.671: [GC (Allocation Failure) [PSYoungGen: 677014K->13795K(246784K)] 826368K->1200063K(1645056K), 0.0322537 secs] [Times: user=0.24 sys=0.01, real=0.04 secs] 
215.703: [Full GC (Ergonomics) [PSYoungGen: 13795K->0K(246784K)] [ParOldGen: 1186267K->153647K(1398272K)] 1200063K->153647K(1645056K), [Metaspace: 51375K->51375K(1095680K)], 0.0633584 secs] [Times: user=0.22 sys=0.00, real=0.06 secs] 
[2018/03/29-12:43:34.474] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:34.483] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
216.009: [GC (Allocation Failure) [PSYoungGen: 232960K->526K(465920K)] 386607K->154173K(1864192K), 0.0018388 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
216.246: [GC (Allocation Failure) [PSYoungGen: 233486K->4945K(465920K)] 387133K->158593K(1864192K), 0.0019647 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
216.479: [GC (Allocation Failure) [PSYoungGen: 237905K->6923K(465920K)] 391553K->160570K(1864192K), 0.0019037 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
216.710: [GC (Allocation Failure) [PSYoungGen: 239883K->5960K(465920K)] 393530K->159608K(1864192K), 0.0018936 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
216.946: [GC (Allocation Failure) [PSYoungGen: 238920K->8721K(465920K)] 392568K->162369K(1864192K), 0.0022262 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
217.179: [GC (Allocation Failure) [PSYoungGen: 241681K->6537K(465920K)] 395329K->160184K(1864192K), 0.0020376 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
217.405: [GC (Allocation Failure) [PSYoungGen: 239497K->8649K(465920K)] 393144K->162296K(1864192K), 0.0021027 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
217.640: [GC (Allocation Failure) [PSYoungGen: 241609K->6504K(465920K)] 395256K->160176K(1864192K), 0.0020419 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
217.878: [GC (Allocation Failure) [PSYoungGen: 239464K->8648K(465920K)] 393136K->162328K(1864192K), 0.0020883 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
218.111: [GC (Allocation Failure) [PSYoungGen: 241608K->6701K(465920K)] 395288K->160389K(1864192K), 0.0023190 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
218.345: [GC (Allocation Failure) [PSYoungGen: 239661K->5543K(465920K)] 393349K->159231K(1864192K), 0.0020137 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
218.578: [GC (Allocation Failure) [PSYoungGen: 238503K->7587K(449536K)] 392191K->161282K(1847808K), 0.0022892 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
218.811: [GC (Allocation Failure) [PSYoungGen: 240547K->9635K(457728K)] 394242K->163330K(1856000K), 0.0024094 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
219.041: [GC (Allocation Failure) [PSYoungGen: 242595K->9869K(436224K)] 396290K->163565K(1834496K), 0.0027566 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
219.289: [GC (Allocation Failure) [PSYoungGen: 262285K->8802K(449536K)] 415981K->162498K(1847808K), 0.0024632 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
219.532: [GC (Allocation Failure) [PSYoungGen: 261218K->11922K(432128K)] 414914K->165617K(1830400K), 0.0021336 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
219.812: [GC (Allocation Failure) [PSYoungGen: 285330K->6504K(444928K)] 439025K->160200K(1843200K), 0.0023616 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
220.134: [GC (Allocation Failure) [PSYoungGen: 279912K->9864K(433664K)] 433608K->163559K(1831936K), 0.0027418 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:38.990] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=67885861
[2018/03/29-12:43:38.990] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:39.001] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:39.001] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
220.618: [GC (Allocation Failure) [PSYoungGen: 304776K->141255K(444928K)] 458471K->1203954K(1843200K), 0.0412348 secs] [Times: user=0.29 sys=0.00, real=0.04 secs] 
220.659: [Full GC (Ergonomics) [PSYoungGen: 141255K->0K(444928K)] [ParOldGen: 1062698K->154274K(1398272K)] 1203954K->154274K(1843200K), [Metaspace: 51401K->51401K(1095680K)], 0.0641421 secs] [Times: user=0.24 sys=0.00, real=0.07 secs] 
[2018/03/29-12:43:39.483] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:39.492] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
221.027: [GC (Allocation Failure) [PSYoungGen: 294912K->943K(492032K)] 449186K->155218K(1890304K), 0.0018983 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
221.366: [GC (Allocation Failure) [PSYoungGen: 332719K->5207K(503808K)] 486994K->159481K(1902080K), 0.0019976 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
221.693: [GC (Allocation Failure) [PSYoungGen: 336983K->9129K(504832K)] 491257K->163404K(1903104K), 0.0020870 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
222.044: [GC (Allocation Failure) [PSYoungGen: 373161K->9903K(517120K)] 527436K->164178K(1915392K), 0.0021635 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
222.411: [GC (Allocation Failure) [PSYoungGen: 373935K->6619K(522240K)] 528210K->160894K(1920512K), 0.0023478 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
222.813: [GC (Allocation Failure) [PSYoungGen: 403931K->11953K(532480K)] 558206K->166227K(1930752K), 0.0021514 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
223.216: [GC (Allocation Failure) [PSYoungGen: 409265K->5476K(537088K)] 563539K->159750K(1935360K), 0.0021743 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
223.632: [GC (Allocation Failure) [PSYoungGen: 434020K->10027K(546816K)] 588294K->164302K(1945088K), 0.0021556 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
224.091: [GC (Allocation Failure) [PSYoungGen: 438571K->4650K(552960K)] 592846K->158925K(1951232K), 0.0021727 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
224.550: [GC (Allocation Failure) [PSYoungGen: 462378K->5468K(561664K)] 616653K->159743K(1959936K), 0.0020565 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
225.009: [GC (Allocation Failure) [PSYoungGen: 463196K->7733K(568320K)] 617471K->162008K(1966592K), 0.0019906 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:44.191] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=69580104
[2018/03/29-12:43:44.192] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
225.486: [GC (Allocation Failure) [PSYoungGen: 493109K->3621K(576512K)] 647384K->157896K(1974784K), 0.0020056 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:44.205] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:44.205] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
Mar 29, 2018 12:42:37 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1460100 records.
Mar 29, 2018 12:42:37 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:37 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 245 ms. row count = 1460100
Mar 29, 2018 12:42:41 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:41 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1690100 records.
Mar 29, 2018 12:42:41 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:41 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 252 ms. row count = 1690100
Mar 29, 2018 12:42:46 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:46 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1690100 records.
Mar 29, 2018 12:42:46 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:47 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 263 ms. row count = 1690100
Mar 29, 2018 12:42:51 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:51 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1694243 records.
Mar 29, 2018 12:42:51 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:52 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 318 ms. row count = 1694243
Mar 29, 2018 12:42:57 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:42:57 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1694243 records.
Mar 29, 2018 12:42:57 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:42:57 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 259 ms. row count = 1694243
Mar 29, 2018 12:43:02 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:43:02 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1690100 records.
Mar 29, 2018 12:43:02 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:43:02 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 298 ms. row count = 1690100
Mar 29, 2018 12:43:08 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:43:08 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1690100 records.
Mar 29, 2018 12:43:08 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:43:08 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 247 ms. row count = 1690100
Mar 29, 2018 12:43:13 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:43:13 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1694243 records.
Mar 29, 2018 12:43:13 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:43:13 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 245 ms. row count = 1694243
Mar 29, 2018 12:43:18 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:43:18 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1690100 records.
Mar 29, 2018 12:43:18 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:43:18 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 220 ms. row count = 1690100
Mar 29, 2018 12:43:23 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:43:23 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1720332 records.
Mar 29, 2018 12:43:23 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:43:24 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 226 ms. row count = 1694243
Mar 29, 2018 12:43:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: Assembled and processed 1694243 records from 10 columns in 4989 ms: 339.5957 rec/ms, 3395.957 cell/ms
Mar 29, 2018 12:43:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: time spent so far 4% reading (226 ms) and 95% processing (4989 ms)
Mar 29, 2018 12:43:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 1694243. reading next block
Mar 29, 2018 12:43:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 0 ms. row count = 26089
Mar 29, 2018 12:43:29 PM INFO: parquet.hadoop.ParquetInputFormat: Total input paths to process : 1
Mar 29, 2018 12:43:29 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:43:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1467510 records.
Mar 29, 2018 12:43:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:43:29 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 368 ms. row count = 1467510
Mar 29, 2018 12:43:33 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:43:33 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1690100 records.
Mar 29, 2018 12:43:33 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:43:34 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 221 ms. row count = 1690100
Mar 29, 2018 12:43:38 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
Mar 29, 2018 12:43:39 PM INFO: parquet.hadoop.InternalParquetRecordReader: RecordReader initialized will read a total of 1694243 records.
Mar 29, 2018 12:43:39 PM INFO: parquet.hadoop.InternalParquetRecordReader: at row 0. reading next block
Mar 29, 2018 12:43:39 PM INFO: parquet.hadoop.InternalParquetRecordReader: block read in memory in 308 ms. row count = 1694243
Mar 29, 2018 12:43:44 PM WARNING: parquet.hadoop.ParquetRecordReader: Can not initialize counter due to context is not a instance of TaskInputOutputContext, but is org.apache.hadoop.mapred.TaskAttemptContextImpl
[2018/03/29-12:43:44.492] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:44.500] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
226.200: [GC (Allocation Failure) [PSYoungGen: 488997K->10617K(601088K)] 643272K->1203505K(1999360K), 0.0376460 secs] [Times: user=0.27 sys=0.02, real=0.04 secs] 
226.238: [Full GC (Ergonomics) [PSYoungGen: 10617K->0K(601088K)] [ParOldGen: 1192888K->153927K(1398272K)] 1203505K->153927K(1999360K), [Metaspace: 51422K->51422K(1095680K)], 0.0650978 secs] [Times: user=0.27 sys=0.00, real=0.07 secs] 
226.827: [GC (Allocation Failure) [PSYoungGen: 520192K->8055K(599552K)] 674119K->161982K(1997824K), 0.0019337 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
227.335: [GC (Allocation Failure) [PSYoungGen: 528247K->7686K(614400K)] 682174K->161613K(2012672K), 0.0029280 secs] [Times: user=0.00 sys=0.01, real=0.00 secs] 
227.875: [GC (Allocation Failure) [PSYoungGen: 551430K->5458K(612864K)] 705357K->159386K(2011136K), 0.0023342 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
228.417: [GC (Allocation Failure) [PSYoungGen: 549202K->9641K(624640K)] 703130K->163568K(2022912K), 0.0032539 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
228.974: [GC (Allocation Failure) [PSYoungGen: 573865K->7683K(624128K)] 727792K->161611K(2022400K), 0.0021459 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
229.521: [GC (Allocation Failure) [PSYoungGen: 571907K->10702K(633856K)] 725835K->164629K(2032128K), 0.0032301 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
230.088: [GC (Allocation Failure) [PSYoungGen: 593358K->6623K(634368K)] 747285K->160551K(2032640K), 0.0028112 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:49.325] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=71270204
[2018/03/29-12:43:49.325] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:49.337] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:49.338] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
230.635: [GC (Allocation Failure) [PSYoungGen: 554244K->2224K(645120K)] 708171K->156159K(2043392K), 0.0037281 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:49.501] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:49.508] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
231.421: [GC (Allocation Failure) [PSYoungGen: 600240K->10929K(644608K)] 754175K->1203035K(2042880K), 0.0340753 secs] [Times: user=0.25 sys=0.00, real=0.04 secs] 
231.456: [Full GC (Ergonomics) [PSYoungGen: 10929K->0K(644608K)] [ParOldGen: 1192105K->153815K(1398272K)] 1203035K->153815K(2042880K), [Metaspace: 51424K->51424K(1095680K)], 0.0664092 secs] [Times: user=0.27 sys=0.00, real=0.07 secs] 
232.122: [GC (Allocation Failure) [PSYoungGen: 598016K->10771K(649216K)] 751831K->164587K(2047488K), 0.0030552 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
232.721: [GC (Allocation Failure) [PSYoungGen: 619027K->10775K(648192K)] 772843K->164590K(2046464K), 0.0023147 secs] [Times: user=0.01 sys=0.01, real=0.01 secs] 
233.340: [GC (Allocation Failure) [PSYoungGen: 619031K->3336K(656896K)] 772846K->157152K(2055168K), 0.0035202 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
233.978: [GC (Allocation Failure) [PSYoungGen: 622856K->7557K(655360K)] 776672K->161373K(2053632K), 0.0027119 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
234.795: [GC (Allocation Failure) [PSYoungGen: 627077K->7561K(660992K)] 780893K->161377K(2059264K), 0.0051502 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
235.558: [GC (Allocation Failure) [PSYoungGen: 635273K->5511K(659456K)] 789089K->159326K(2057728K), 0.0028677 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:54.509] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:54.517] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
[2018/03/29-12:43:54.953] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=72964733
[2018/03/29-12:43:54.953] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:43:54.964] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:43:54.964] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
236.261: [GC (Allocation Failure) [PSYoungGen: 608638K->4918K(664576K)] 762454K->158741K(2062848K), 0.0032095 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
237.148: [GC (Allocation Failure) [PSYoungGen: 639798K->9198K(663552K)] 793621K->1202942K(2061824K), 0.0502212 secs] [Times: user=0.31 sys=0.00, real=0.05 secs] 
237.199: [Full GC (Ergonomics) [PSYoungGen: 9198K->0K(663552K)] [ParOldGen: 1193743K->154033K(1398272K)] 1202942K->154033K(2061824K), [Metaspace: 51433K->51433K(1095680K)], 0.0741593 secs] [Times: user=0.20 sys=0.00, real=0.08 secs] 
237.980: [GC (Allocation Failure) [PSYoungGen: 634880K->9745K(668160K)] 788913K->163779K(2066432K), 0.0046206 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
238.643: [GC (Allocation Failure) [PSYoungGen: 651281K->6551K(667136K)] 805315K->160585K(2065408K), 0.0027783 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
239.480: [GC (Allocation Failure) [PSYoungGen: 648087K->5445K(671744K)] 802121K->159479K(2070016K), 0.0025332 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
240.369: [GC (Allocation Failure) [PSYoungGen: 653125K->6503K(670720K)] 807159K->160537K(2068992K), 0.0023994 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
[2018/03/29-12:43:59.517] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:43:59.527] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
241.024: [GC (Allocation Failure) [PSYoungGen: 654183K->5679K(674816K)] 808217K->159712K(2073088K), 0.0022577 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
241.682: [GC (Allocation Failure) [PSYoungGen: 658479K->6589K(673792K)] 812512K->160622K(2072064K), 0.0029043 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:44:00.793] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=74658976
[2018/03/29-12:44:00.793] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:00.804] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:00.805] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
242.534: [GC (Allocation Failure) [PSYoungGen: 659389K->10078K(676352K)] 813422K->1202253K(2074624K), 0.0573582 secs] [Times: user=0.36 sys=0.00, real=0.05 secs] 
242.591: [Full GC (Ergonomics) [PSYoungGen: 10078K->0K(676352K)] [ParOldGen: 1192175K->153792K(1398272K)] 1202253K->153792K(2074624K), [Metaspace: 51446K->51446K(1095680K)], 0.0642708 secs] [Times: user=0.26 sys=0.00, real=0.07 secs] 
243.340: [GC (Allocation Failure) [PSYoungGen: 656384K->5636K(675840K)] 810176K->159428K(2074112K), 0.0019331 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
244.017: [GC (Allocation Failure) [PSYoungGen: 662020K->7614K(678400K)] 815812K->161406K(2076672K), 0.0022365 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
244.679: [GC (Allocation Failure) [PSYoungGen: 668094K->6715K(678400K)] 821886K->160507K(2076672K), 0.0021531 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
245.406: [GC (Allocation Failure) [PSYoungGen: 667195K->10775K(679424K)] 820987K->164567K(2077696K), 0.0030259 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
[2018/03/29-12:44:04.527] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
246.072: [GC (Allocation Failure) [PSYoungGen: 673303K->5567K(679936K)] 827095K->159360K(2078208K), 0.0022932 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
246.737: [GC (Allocation Failure) [PSYoungGen: 668095K->13108K(679936K)] 821888K->166900K(2078208K), 0.0029279 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
[2018/03/29-12:44:06.092] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=76353219
[2018/03/29-12:44:06.093] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:06.099] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:06.100] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
247.396: [GC (Allocation Failure) [PSYoungGen: 662406K->5097K(680960K)] 816198K->158889K(2079232K), 0.0018931 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:44:06.243] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
248.398: [GC (Allocation Failure) [PSYoungGen: 668137K->10336K(680448K)] 821929K->1203170K(2078720K), 0.0564035 secs] [Times: user=0.33 sys=0.00, real=0.06 secs] 
248.455: [Full GC (Ergonomics) [PSYoungGen: 10336K->0K(680448K)] [ParOldGen: 1192833K->153875K(1398272K)] 1203170K->153875K(2078720K), [Metaspace: 51448K->51448K(1095680K)], 0.0646223 secs] [Times: user=0.21 sys=0.00, real=0.06 secs] 
249.202: [GC (Allocation Failure) [PSYoungGen: 663552K->10812K(680960K)] 817427K->164687K(2079232K), 0.0022085 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
249.906: [GC (Allocation Failure) [PSYoungGen: 674364K->5409K(680448K)] 828239K->159285K(2078720K), 0.0077256 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
250.583: [GC (Allocation Failure) [PSYoungGen: 669473K->6556K(680960K)] 823349K->160432K(2079232K), 0.0027119 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
251.260: [GC (Allocation Failure) [PSYoungGen: 670620K->7560K(680960K)] 824496K->161435K(2079232K), 0.0021379 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
251.966: [GC (Allocation Failure) [PSYoungGen: 673160K->8726K(681472K)] 827035K->162602K(2079744K), 0.0021583 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:44:11.243] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:44:11.252] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
252.620: [GC (Allocation Failure) [PSYoungGen: 674326K->10760K(683008K)] 828202K->164635K(2081280K), 0.0021205 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:44:11.561] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=78047748
[2018/03/29-12:44:11.561] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:11.568] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:11.568] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
253.435: [GC (Allocation Failure) [PSYoungGen: 678408K->9959K(683008K)] 832283K->1202916K(2081280K), 0.0570118 secs] [Times: user=0.34 sys=0.00, real=0.06 secs] 
253.492: [Full GC (Ergonomics) [PSYoungGen: 9959K->0K(683008K)] [ParOldGen: 1192956K->153944K(1398272K)] 1202916K->153944K(2081280K), [Metaspace: 51457K->51457K(1095680K)], 0.0685541 secs] [Times: user=0.18 sys=0.00, real=0.06 secs] 
254.239: [GC (Allocation Failure) [PSYoungGen: 667648K->8952K(682496K)] 821592K->162897K(2080768K), 0.0020417 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
254.893: [GC (Allocation Failure) [PSYoungGen: 677112K->9747K(683008K)] 831057K->163692K(2081280K), 0.0020684 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
255.549: [GC (Allocation Failure) [PSYoungGen: 677907K->3487K(683008K)] 831852K->157431K(2081280K), 0.0020547 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
256.206: [GC (Allocation Failure) [PSYoungGen: 671647K->9661K(683520K)] 825591K->163606K(2081792K), 0.0021278 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
256.864: [GC (Allocation Failure) [PSYoungGen: 677821K->8581K(682496K)] 831766K->162525K(2080768K), 0.0022013 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
257.524: [GC (Allocation Failure) [PSYoungGen: 677253K->7589K(683008K)] 831197K->161534K(2081280K), 0.0019745 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:44:16.252] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:44:16.261] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
[2018/03/29-12:44:16.650] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=79741991
[2018/03/29-12:44:16.650] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:16.657] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:16.657] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
258.339: [GC (Allocation Failure) [PSYoungGen: 676261K->8124K(683520K)] 830206K->878722K(2081792K), 0.0422131 secs] [Times: user=0.24 sys=0.00, real=0.04 secs] 
258.381: [Full GC (Ergonomics) [PSYoungGen: 8124K->0K(683520K)] [ParOldGen: 870597K->126435K(1398272K)] 878722K->126435K(2081792K), [Metaspace: 51467K->51467K(1095680K)], 0.0648425 secs] [Times: user=0.25 sys=0.00, real=0.07 secs] 
259.129: [GC (Allocation Failure) [PSYoungGen: 670720K->5766K(684032K)] 797155K->132201K(2082304K), 0.0025308 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
259.794: [GC (Allocation Failure) [PSYoungGen: 676486K->12737K(682496K)] 802921K->139172K(2080768K), 0.0024386 secs] [Times: user=0.01 sys=0.01, real=0.00 secs] 
260.474: [GC (Allocation Failure) [PSYoungGen: 681921K->7585K(684032K)] 808356K->134021K(2082304K), 0.0023077 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
261.146: [GC (Allocation Failure) [PSYoungGen: 676769K->8838K(682496K)] 803205K->135274K(2080768K), 0.0026803 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
261.815: [GC (Allocation Failure) [PSYoungGen: 678534K->10929K(683520K)] 804970K->137364K(2081792K), 0.0022242 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:44:20.909] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=81122833
[2018/03/29-12:44:20.909] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing DSS stream, dssSplitRecords=81122833 totalRecords=81122833
[2018/03/29-12:44:20.911] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Extracting Parquet input:/apps/hive/warehouse/data_dev.db/adobe_aam_parquet/000046_0 with ugi: dataiku (auth:SIMPLE)
[2018/03/29-12:44:20.931] [FRT-95-FlowRunnable] [INFO] [org.apache.hadoop.mapreduce.lib.input.FileInputFormat] act.compute_aam_bulk_extract_only_folders_NP - Total input paths to process : 1
[2018/03/29-12:44:20.932] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:20.938] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:20.938] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:44:21.262] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:44:21.268] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
262.602: [GC (Allocation Failure) [PSYoungGen: 680625K->5911K(684544K)] 807060K->1159778K(2082816K), 0.0535396 secs] [Times: user=0.35 sys=0.00, real=0.06 secs] 
262.655: [Full GC (Ergonomics) [PSYoungGen: 5911K->0K(684544K)] [ParOldGen: 1153867K->149363K(1398272K)] 1159778K->149363K(2082816K), [Metaspace: 51477K->51477K(1095680K)], 0.0503459 secs] [Times: user=0.20 sys=0.00, real=0.05 secs] 
263.346: [GC (Allocation Failure) [PSYoungGen: 670208K->6731K(677376K)] 819571K->156094K(2075648K), 0.0022796 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
263.993: [GC (Allocation Failure) [PSYoungGen: 676939K->13037K(681984K)] 826302K->162400K(2080256K), 0.0022628 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
264.639: [GC (Allocation Failure) [PSYoungGen: 681197K->5472K(683520K)] 830560K->154835K(2081792K), 0.0024503 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
265.294: [GC (Allocation Failure) [PSYoungGen: 673632K->11694K(681984K)] 822995K->161057K(2080256K), 0.0021824 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
265.970: [GC (Allocation Failure) [PSYoungGen: 678830K->10696K(683008K)] 828193K->160059K(2081280K), 0.0021745 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:44:25.277] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=82590343
[2018/03/29-12:44:25.277] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:25.284] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:25.284] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
266.581: [GC (Allocation Failure) [PSYoungGen: 652879K->2550K(681984K)] 802242K->151914K(2080256K), 0.0022967 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
267.479: [GC (Allocation Failure) [PSYoungGen: 668662K->11852K(678400K)] 818026K->1199632K(2076672K), 0.0334760 secs] [Times: user=0.24 sys=0.00, real=0.04 secs] 
267.512: [Full GC (Ergonomics) [PSYoungGen: 11852K->0K(678400K)] [ParOldGen: 1187779K->153767K(1398272K)] 1199632K->153767K(2076672K), [Metaspace: 51477K->51477K(1095680K)], 0.0644735 secs] [Times: user=0.22 sys=0.00, real=0.06 secs] 
[2018/03/29-12:44:26.283] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:44:26.291] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
268.219: [GC (Allocation Failure) [PSYoungGen: 666112K->3669K(681984K)] 819879K->157437K(2080256K), 0.0020131 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
268.913: [GC (Allocation Failure) [PSYoungGen: 668757K->6589K(671744K)] 822525K->160357K(2070016K), 0.0021816 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
269.546: [GC (Allocation Failure) [PSYoungGen: 671677K->8544K(682496K)] 825445K->162312K(2080768K), 0.0023092 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
270.182: [GC (Allocation Failure) [PSYoungGen: 674656K->5861K(681472K)] 828424K->159629K(2079744K), 0.0021138 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
270.897: [GC (Allocation Failure) [PSYoungGen: 671973K->9633K(682496K)] 825741K->163401K(2080768K), 0.0029541 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
271.551: [GC (Allocation Failure) [PSYoungGen: 676769K->4329K(682496K)] 830537K->158097K(2080768K), 0.0025923 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:44:30.464] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=84284872
[2018/03/29-12:44:30.464] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:30.471] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:30.471] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
272.320: [GC (Allocation Failure) [PSYoungGen: 671465K->11021K(682496K)] 825233K->1201646K(2080768K), 0.0456371 secs] [Times: user=0.31 sys=0.01, real=0.05 secs] 
272.365: [Full GC (Ergonomics) [PSYoungGen: 11021K->0K(682496K)] [ParOldGen: 1190625K->153660K(1398272K)] 1201646K->153660K(2080768K), [Metaspace: 51480K->51480K(1095680K)], 0.0678509 secs] [Times: user=0.28 sys=0.00, real=0.07 secs] 
[2018/03/29-12:44:31.291] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:44:31.298] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
273.109: [GC (Allocation Failure) [PSYoungGen: 667136K->5773K(683008K)] 820796K->159433K(2081280K), 0.0023211 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
273.776: [GC (Allocation Failure) [PSYoungGen: 672909K->12737K(681472K)] 826569K->166397K(2079744K), 0.0020916 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
274.425: [GC (Allocation Failure) [PSYoungGen: 678849K->10769K(682496K)] 832509K->164430K(2080768K), 0.0021045 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
275.066: [GC (Allocation Failure) [PSYoungGen: 676881K->5509K(682496K)] 830542K->159169K(2080768K), 0.0024629 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] 
275.708: [GC (Allocation Failure) [PSYoungGen: 671621K->8644K(674816K)] 825281K->162304K(2073088K), 0.0021994 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
276.351: [GC (Allocation Failure) [PSYoungGen: 674756K->7619K(683008K)] 828416K->161279K(2081280K), 0.0020311 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:44:35.454] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=85974972
[2018/03/29-12:44:35.454] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:35.461] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:35.461] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
277.183: [GC (Allocation Failure) [PSYoungGen: 674755K->9767K(681984K)] 828415K->1199271K(2080256K), 0.0467566 secs] [Times: user=0.32 sys=0.01, real=0.04 secs] 
277.230: [Full GC (Ergonomics) [PSYoungGen: 9767K->0K(681984K)] [ParOldGen: 1189503K->153477K(1398272K)] 1199271K->153477K(2080256K), [Metaspace: 51490K->51490K(1095680K)], 0.0688624 secs] [Times: user=0.27 sys=0.00, real=0.07 secs] 
[2018/03/29-12:44:36.298] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:44:36.305] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
277.987: [GC (Allocation Failure) [PSYoungGen: 667136K->6708K(683008K)] 820613K->160193K(2081280K), 0.0020221 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
278.663: [GC (Allocation Failure) [PSYoungGen: 674868K->5568K(683008K)] 828353K->159053K(2081280K), 0.0022568 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
279.328: [GC (Allocation Failure) [PSYoungGen: 673728K->7615K(683520K)] 827213K->161100K(2081792K), 0.0021987 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
279.993: [GC (Allocation Failure) [PSYoungGen: 677311K->10694K(683520K)] 830796K->164180K(2081792K), 0.0022311 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
280.651: [GC (Allocation Failure) [PSYoungGen: 680390K->12856K(682496K)] 833876K->166341K(2080768K), 0.0021496 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
281.291: [GC (Allocation Failure) [PSYoungGen: 681016K->7806K(683520K)] 834501K->161291K(2081792K), 0.0020175 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
[2018/03/29-12:44:40.576] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=87665072
[2018/03/29-12:44:40.576] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:40.587] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:40.588] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
281.884: [GC (Allocation Failure) [PSYoungGen: 623552K->1339K(683008K)] 777037K->154824K(2081280K), 0.0026996 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:44:41.305] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
[2018/03/29-12:44:41.311] [Thread-17] [INFO] [dku.job.slave]  - Status update sent
282.736: [GC (Allocation Failure) [PSYoungGen: 669499K->7696K(683520K)] 822984K->1199486K(2081792K), 0.0535618 secs] [Times: user=0.32 sys=0.00, real=0.05 secs] 
282.790: [Full GC (Ergonomics) [PSYoungGen: 7696K->0K(683520K)] [ParOldGen: 1191789K->153809K(1398272K)] 1199486K->153809K(2081792K), [Metaspace: 51497K->51497K(1095680K)], 0.0660624 secs] [Times: user=0.28 sys=0.00, real=0.07 secs] 
283.564: [GC (Allocation Failure) [PSYoungGen: 667897K->8891K(682496K)] 821706K->162700K(2080768K), 0.0021286 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
284.247: [GC (Allocation Failure) [PSYoungGen: 677563K->6504K(683008K)] 831372K->160314K(2081280K), 0.0024914 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
284.964: [GC (Allocation Failure) [PSYoungGen: 675176K->7485K(683520K)] 828986K->161294K(2081792K), 0.0054432 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
285.692: [GC (Allocation Failure) [PSYoungGen: 677693K->5405K(684032K)] 831502K->159214K(2082304K), 0.0038552 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
286.392: [GC (Allocation Failure) [PSYoungGen: 675613K->7516K(684032K)] 829422K->161326K(2082304K), 0.0024333 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
287.142: [GC (Allocation Failure) [PSYoungGen: 679260K->7576K(684544K)] 833070K->161386K(2082816K), 0.0044717 secs] [Times: user=0.00 sys=0.00, real=0.01 secs] 
[2018/03/29-12:44:46.054] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Done processing Hadoop split, dssSplitRecords=89359315
[2018/03/29-12:44:46.055] [FRT-95-FlowRunnable] [INFO] [dku.formats.parquet] act.compute_aam_bulk_extract_only_folders_NP - Processing Hadoop split
[2018/03/29-12:44:46.061] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Input Parquet MessageType: 
message hive_schema {
  optional binary aamid_hash (UTF8);
  optional binary trait (UTF8);
  optional binary epoch_timestamp (UTF8);
  optional binary region_code (UTF8);
  optional binary timestamp_as_date (UTF8);
  optional binary timestamp_year (UTF8);
  optional binary timestamp_month (UTF8);
  optional binary timestamp_day (UTF8);
  optional binary ingestion_timestamp (UTF8);
  optional binary filename (UTF8);
}

[2018/03/29-12:44:46.061] [FRT-95-FlowRunnable] [INFO] [com.dataiku.dip.input.formats.parquet.RowTupleConverter] act.compute_aam_bulk_extract_only_folders_NP - Detected Parquet flavor: HIVE
[2018/03/29-12:44:46.312] [Thread-17] [INFO] [dku.job.slave]  - Sending status update
288.055: [GC (Allocation Failure) [PSYoungGen: 679320K->10336K(685568K)] 833130K->1202601K(2083840K), 0.0527005 secs] [Times: user=0.34 sys=0.00, real=0.05 secs] 
288.107: [Full GC (Ergonomics) [PSYoungGen: 10336K->0K(685568K)] [ParOldGen: 1192265K->153824K(1398272K)] 1202601K->153824K(2083840K), [Metaspace: 51497K->51497K(1095680K)], 0.0714806 secs] [Times: user=0.21 sys=0.00, real=0.07 secs] 
288.871: [GC (Allocation Failure) [PSYoungGen: 673280K->4595K(686080K)] 827104K->158420K(2084352K), 0.0021166 secs] [Times: user=0.01 sys=0.00, real=0.01 secs] 
289.530: [GC (Allocation Failure) [PSYoungGen: 677875K->9787K(685056K)] 831700K->163611K(2083328K), 0.0023832 secs] [Times: user=0.01 sys=0.01, real=0.01 secs] 
290.284: [GC (Allocation Failure) [PSYoungGen: 682043K->6531K(685568K)] 835867K->160356K(2083840K), 0.0022974 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
290.990: [GC (Allocation Failure) [PSYoungGen: 678787K->8552K(685568K)] 832612K->162376K(2083840K), 0.0046142 secs] [Times: user=0.02 sys=0.00, real=0.01 secs] 
291.693: [GC (Allocation Failure) [PSYoungGen: 681320K->9709K(685568K)] 835144K->163533K(2083840K), 0.0022273 secs] [Times: user=0.01 sys=0.00, real=0.00 secs] 
[2018/03/29-12:44:50.851] [FRT-95-FlowRunnable] [DEBUG] [dku.connections.sql.provider] act.compute_aam_bulk_extract_only_folders_NP - Close conn=h2connection
[2018/03/29-12:44:50.854] [FRT-95-FlowRunnable] [DEBUG] [dku.connections.sql.provider] act.compute_aam_bulk_extract_only_folders_NP - Close conn=h2connection
[2018/03/29-12:44:50.854] [FRT-95-FlowRunnable] [INFO] [dku.flow.activity] act.compute_aam_bulk_extract_only_folders_NP - Run thread failed for activity compute_aam_bulk_extract_only_folders_NP
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:221)
	at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:282)
	at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:125)
	at java.io.OutputStreamWriter.write(OutputStreamWriter.java:207)
	at java.io.BufferedWriter.flushBuffer(BufferedWriter.java:129)
	at java.io.BufferedWriter.write(BufferedWriter.java:230)
	at java.io.Writer.write(Writer.java:157)
	at java.io.Writer.append(Writer.java:227)
	at com.dataiku.dip.output.CSVOutputFormatter.appendUNIXStyle(CSVOutputFormatter.java:64)
	at com.dataiku.dip.output.CSVOutputFormatter.appendFieldToLine(CSVOutputFormatter.java:201)
	at com.dataiku.dip.output.CSVOutputFormatter.format(CSVOutputFormatter.java:183)
	at com.dataiku.dip.output.StringOutputFormatter.format(StringOutputFormatter.java:32)
	at com.dataiku.dip.output.OutputStreamOutputWriter.emitRow(OutputStreamOutputWriter.java:32)
	at com.dataiku.dip.dataflow.exec.h2.DatasetToH2Loader$AbortableProcessorOutput.emitRow(DatasetToH2Loader.java:277)
	at com.dataiku.dip.input.formats.parquet.ParquetFormatExtractor$1.run(ParquetFormatExtractor.java:135)
	at com.dataiku.dip.input.formats.parquet.ParquetFormatExtractor$1.run(ParquetFormatExtractor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at com.dataiku.dip.util.HadoopUtils.fixedUpDoAs(HadoopUtils.java:36)
	at com.dataiku.dip.input.formats.parquet.ParquetFormatExtractor.run(ParquetFormatExtractor.java:106)
	at com.dataiku.dip.datasets.AbstractSingleThreadPusher.pushSplits(AbstractSingleThreadPusher.java:180)
	at com.dataiku.dip.datasets.UniversalSingleThreadPusher.push(UniversalSingleThreadPusher.java:234)
	at com.dataiku.dip.dataflow.exec.h2.DatasetToH2Loader.dumpToCSV(DatasetToH2Loader.java:136)
	at com.dataiku.dip.dataflow.exec.h2.DatasetToH2Loader.load(DatasetToH2Loader.java:164)
	at com.dataiku.dip.dataflow.exec.h2.H2RecipeRunner.run(H2RecipeRunner.java:146)
	at com.dataiku.dip.dataflow.exec.MultiEngineRecipeRunner.run(MultiEngineRecipeRunner.java:191)
	at com.dataiku.dip.dataflow.jobrunner.ActivityRunner$FlowRunnableThread.run(ActivityRunner.java:352)
[2018/03/29-12:44:50.888] [ActivityExecutor-35] [INFO] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - activity is finished
[2018/03/29-12:44:50.888] [ActivityExecutor-35] [ERROR] [dku.flow.activity] running compute_aam_bulk_extract_only_folders_NP - Activity failed
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:326)
	at sun.nio.cs.StreamEncoder.writeBytes(StreamEncoder.java:221)
	at sun.nio.cs.StreamEncoder.implWrite(StreamEncoder.java:282)
	at sun.nio.cs.StreamEncoder.write(StreamEncoder.java:125)
	at java.io.OutputStreamWriter.write(OutputStreamWriter.java:207)
	at java.io.BufferedWriter.flushBuffer(BufferedWriter.java:129)
	at java.io.BufferedWriter.write(BufferedWriter.java:230)
	at java.io.Writer.write(Writer.java:157)
	at java.io.Writer.append(Writer.java:227)
	at com.dataiku.dip.output.CSVOutputFormatter.appendUNIXStyle(CSVOutputFormatter.java:64)
	at com.dataiku.dip.output.CSVOutputFormatter.appendFieldToLine(CSVOutputFormatter.java:201)
	at com.dataiku.dip.output.CSVOutputFormatter.format(CSVOutputFormatter.java:183)
Mar 29, 2018 12:43:44 PM INFO: parquet.hadoop.InternalParquFailed to log per-activity line: No space left on device
	at com.dataiku.dip.output.StringOutputFormatter.format(StringOutputFormatter.java:32)
	at com.dataiku.dip.output.OutputStreamOutputWriter.emitRow(OutputStreamOutputWriter.java:32)
	at com.dataiku.dip.dataflow.exec.h2.DatasetToH2Loader$AbortableProcessorOutput.emitRow(DatasetToH2Loader.java:277)
	at com.dataiku.dip.input.formats.parquet.ParquetFormatExtractor$1.run(ParquetFormatExtractor.java:135)
	at com.dataiku.dip.input.formats.parquet.ParquetFormatExtractor$1.run(ParquetFormatExtractor.java:106)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)
	at com.dataiku.dip.util.HadoopUtils.fixedUpDoAs(HadoopUtils.java:36)
	at com.dataiku.dip.input.formats.parquet.ParquetFormatExtractor.run(ParquetFormatExtractor.java:106)
	at com.dataiku.dip.datasets.AbstractSingleThreadPusher.pushSplits(AbstractSingleThreadPusher.java:180)
	at com.dataiku.dip.datasets.UniversalSingleThreadPusher.push(UniversalSingleThreadPusher.java:234)
	at com.dataiku.dip.dataflow.exec.h2.DatasetToH2Loader.dumpToCSV(DatasetToH2Loader.java:136)
	at com.dataiku.dip.dataflow.exec.h2.DatasetToH2Loader.load(DatasetToH2Loader.java:164)
	at com.dataiku.dip.dataflow.exec.h2.H2RecipeRunner.run(H2RecipeRunner.java:146)
	at com.dataiku.dip.dataflow.exec.MultiEngineRecipeRunner.run(MultiEngineRecipeRunner.java:191)
	at com.dataiku.dip.dataflow.jobrunner.ActivityRunner$FlowRunnableThread.run(ActivityRunner.java:352)
Failed to log per-job line: No space left on device
java.io.IOException: No space left on device
	at java.io.FileOutputStream.writeBytes(Native Method)
	at java.io.FileOutputStream.write(FileOutputStream.java:313)
	at org.apache.commons.io.IOUtils.write(IOUtils.java:1527)
	at org.apache.commons.io.FileUtils.writeStringToFile(FileUtils.java:1929)
	at org.apache.commons.io.FileUtils.writeSt